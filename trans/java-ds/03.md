# 三、数据清理

真实世界的数据通常是脏的和非结构化的，并且在可用之前必须重新处理。数据可能包含错误、重复条目、格式错误或不一致。解决这些类型问题的过程称为**数据清理**。数据清洗又被称为**数据角力**、**按摩**、**整形**，或者**蒙皮**。数据合并是指将来自多个来源的数据进行合并，通常被认为是一种数据清理活动。

我们需要清理数据，因为任何基于不准确数据的分析都会产生误导性的结果。我们希望确保我们处理的数据是高质量的数据。数据质量包括:

*   **有效性**:确保数据具有正确的形式或结构
*   **准确性:**数据中的值真正代表数据集
*   **完整性:**没有缺失的元素
*   **一致性**:数据的变化是同步的
*   **一致性**:使用相同的测量单位

有几种用于清理数据的技术和工具。我们将研究以下方法:

*   处理不同类型的数据
*   清理和操作文本数据
*   填补缺失数据
*   验证数据

此外，我们将简要检查几种图像增强技术。

通常有许多方法来完成相同的清洁任务。例如，有许多支持数据清理的 GUI 工具，比如 open refine([http://openrefine.org/](http://openrefine.org/))。该工具允许用户读入数据集，并使用各种技术对其进行清理。然而，对于需要清理的每个数据集，它需要用户与应用程序进行交互。它不利于自动化。

我们将关注如何使用 Java 代码清理数据。即便如此，也可能有不同的技术来清理数据。我们将展示多种方法，为读者提供如何做到这一点的见解。有时，这将使用核心 Java 字符串类，而在其他时候，它可能会使用专门的库。

这些库通常更具表现力和效率。但是，有时使用简单的字符串函数就足以解决问题了。展示赞美的技巧会提高读者的技能。

基于文本的基本任务包括:

*   数据转换
*   数据插补(处理缺失数据)
*   子集数据
*   分类数据
*   验证数据

在这一章中，我们感兴趣的是清理数据。然而，这个过程的一部分是从各种数据源中提取信息。数据可以明文或二进制形式存储。在开始清理过程之前，我们需要了解用于存储数据的各种格式。这些格式中的许多已在第 2 章、*数据采集*中介绍过，但我们将在以下章节中更详细地介绍。

# 处理数据格式

数据以各种形式出现。我们将研究更常用的格式，并展示如何从各种数据源中提取它们。在我们清理数据之前，需要从数据源(如文件)中提取数据。在本节中，我们将建立在[第 2 章](part0029.xhtml#aid-RL0A2 "Chapter 2. Data Acquisition")、*数据采集*中的数据格式介绍的基础上，并展示如何提取全部或部分数据集。例如，从一个 HTML 页面中，我们可能只想提取没有标记的文本。或者也许我们只对它的数字感兴趣。

这些数据格式可能相当复杂。本节的目的是说明该数据格式常用的基本技术。对特定数据格式的全面论述超出了本书的范围。具体来说，我们将介绍如何从 Java 处理以下数据格式:

*   CSV 数据
*   电子表格
*   可移植文档格式或 PDF 文件
*   Javascript 对象符号或 JSON 文件

还有许多其他文件类型在这里没有提到。例如，jsoup 对于解析 HTML 文档很有用。因为我们已经在第二章、*数据采集*的[Java 部分介绍了这是如何完成的，所以我们在此不再赘述。](part0029.xhtml#aid-RL0A2 "Chapter 2. Data Acquisition")

## 处理 CSV 数据

分隔信息的常用技术是使用逗号或类似的分隔符。了解如何处理 CSV 数据使我们能够在分析工作中利用这种类型的数据。当我们处理 CSV 数据时，有几个问题，包括转义数据和嵌入的逗号。

我们将研究一些处理逗号分隔数据的基本技术。由于 CSV 数据的行列结构，这些技术将从文件中读取数据，并将数据放在二维数组中。首先，我们将结合使用`Scanner`类读入令牌和`String`类`split`方法来分离数据并将其存储在数组中。接下来，我们将探索使用第三方库 OpenCSV，它提供了一种更有效的技术。

然而，第一种方法可能只适用于快速和肮脏的数据处理。我们将逐一讨论这些技术，因为它们在不同的情况下都很有用。

我们将使用从[https://www.data.gov/](https://www.data.gov/)下载的数据集，其中包含按邮政编码排序的美国人口统计数据。该数据集可在[https://catalog . data . gov/dataset/demographic-statistics-by-zip-code-acfc 9](https://catalog.data.gov/dataset/demographic-statistics-by-zip-code-acfc9)下载。出于我们的目的，这个数据集已经存储在文件`Demographics.csv`中。在这个特定的文件中，每一行都包含相同数量的列。然而，并不是所有的数据都如此干净，接下来显示的解决方案考虑了交错数组的可能性。

### 注意

交错数组是指不同行的列数可能不同的数组。例如，行 2 可以具有 5 个元素，而行 3 可以具有 6 个元素。当使用交错数组时，你必须小心你的列索引。

首先，我们使用`Scanner`类从数据文件中读入数据。我们将数据暂时存储在一个`ArrayList`中，因为我们并不总是知道我们的数据包含多少行。

```
try (Scanner csvData = new Scanner(new File("Demographics.csv"))) {
    ArrayList<String> list = new ArrayList<String>();         
    while (csvData.hasNext()) {             
        list.add(csvData.nextLine());     
} catch (FileNotFoundException ex) {     
    // Handle exceptions 
} 

```

使用`toArray`方法将列表转换为数组。这个版本的方法使用一个`String`数组作为参数，这样该方法就知道要创建什么类型的数组。然后创建一个二维数组来保存 CSV 数据。

```
String[] tempArray = list.toArray(new String[1]); 
String[][] csvArray = new String[tempArray.length][]; 

```

`split`方法用于为每行创建一个由`String`组成的数组。这个数组被分配给`csvArray`的一行。

```
for(int i=0; i<tempArray.length; i++) { 
    csvArray[i] = tempArray[i].split(","); 
} 

```

我们的下一项技术将使用第三方库来读入和处理 CSV 数据。有多种选择，但我们将重点关注流行的 OpenCSV([http://opencsv.sourceforge.net](http://opencsv.sourceforge.net))。这个库比我们以前的技术提供了几个优势。我们可以在每行上有任意数量的条目，而不用担心处理异常。我们也不需要担心数据标记中嵌入的逗号或回车。该库还允许我们选择一次读取整个文件还是使用迭代器逐行处理数据。

首先，我们需要创建一个`CSVReader`类的实例。注意，第二个参数允许我们指定分隔符，例如，如果我们有由制表符或破折号分隔的类似文件格式，这是一个有用的特性。如果我们想一次读取整个文件，我们使用`readAll`方法。

```
CSVReader dataReader = new CSVReader(new    FileReader("Demographics.csv"),','); 
ArrayList<String> holdData = (ArrayList)dataReader.readAll();
```

然后我们可以像上面一样处理数据，通过使用`String`类方法将数据分割成一个二维数组。或者，我们可以一次处理一行数据。在下面的示例中，每个标记都是单独打印出来的，但是标记也可以存储在二维数组或其他适当的数据结构中。

```
CSVReader dataReader = new CSVReader(new    FileReader("Demographics.csv"),','); 
String[] nextLine; 
while ((nextLine = dataReader.readNext()) != null){ 
for(String token : nextLine){ 
    out.println(token); 
  } 
} 
dataReader.close(); 

```

我们现在可以清理或处理阵列。

## 处理电子表格

电子表格已经被证明是一种非常流行的处理数字和文本数据的工具。由于过去几十年来电子表格中存储了大量信息，知道如何从电子表格中提取信息使我们能够利用这一广泛可用的数据源。在本节中，我们将演示如何使用 Apache POI API 来实现这一点。

Open Office 还支持电子表格应用程序。Open Office 文档以 XML 格式存储，这使得使用 XML 解析技术很容易访问它。然而，阿帕奇 ODF 工具包([http://incubator.apache.org/odftoolkit/](http://incubator.apache.org/odftoolkit/))提供了一种在不知道 OpenOffice 文档格式的情况下访问文档内数据的方法。这目前是一个孵化器项目，还没有完全成熟。还有许多其他 API 可以帮助处理 OpenOffice 文档，详见面向开发人员的**开放文档格式**(**ODF**)([http://www.opendocumentformat.org/developers/](http://www.opendocumentformat.org/developers/))页面。

### 处理 Excel 电子表格

Apache POI([http://poi.apache.org/index.html](http://poi.apache.org/index.html))是一组 API，提供对包括 Excel 和 Word 在内的许多微软产品的访问。它由一系列旨在访问特定 Microsoft 产品的组件组成。这些组件的概述可在 http://poi.apache.org/overview.html 的[找到。](http://poi.apache.org/overview.html)

在本节中，我们将演示如何使用 XSSF 组件读取一个简单的 Excel 电子表格来访问 Excel 2007+电子表格。Apache POI API 的 Javadocs 可以在[https://poi.apache.org/apidocs/index.html](https://poi.apache.org/apidocs/index.html)找到。

我们将使用一个简单的 Excel 电子表格，它由一系列包含 ID 以及最小值、最大值和平均值的行组成。这些数字并不代表任何特定类型的数据。电子表格如下:

| **ID** | **最小值** | **最大值** | **平均值** |
| `12345` | `45` | `89` | `65.55` |
| `23456` | `78` | `96` | `86.75` |
| `34567` | `56` | `89` | `67.44` |
| `45678` | `86` | `99` | `95.67` |

我们从 try-with-resources 块开始处理任何可能发生的`IOExceptions`:

```
try (FileInputStream file = new FileInputStream( 
        new File("Sample.xlsx"))) { 
    ... 
    } 
} catch (IOException e) { 
    // Handle exceptions 
} 

```

使用电子表格创建一个`XSSFWorkbook`类的实例。由于一个工作簿可能包含多个电子表格，我们使用`getSheetAt`方法选择第一个。

```
XSSFWorkbook workbook = new XSSFWorkbook(file); 
XSSFSheet sheet = workbook.getSheetAt(0); 

```

下一步是遍历电子表格的行，然后遍历每一列:

```
for(Row row : sheet) { 
    for (Cell cell : row) { 
        ... 
    } 
out.println(); 

```

电子表格的每个单元格可以使用不同的格式。我们使用`getCellType`方法确定其类型，然后使用适当的方法提取单元格中的数据。在这个例子中，我们只处理数字和文本数据。

```
switch (cell.getCellType()) { 
    case Cell.CELL_TYPE_NUMERIC: 
        out.print(cell.getNumericCellValue() + "\t"); 
        break; 
    case Cell.CELL_TYPE_STRING: 
        out.print(cell.getStringCellValue() + "\t"); 
        break; 
   } 

```

执行时，我们得到以下输出:

```
ID Minimum Maximum Average 
12345.0 45.0 89.0 65.55
23456.0 78.0 96.0 86.75
34567.0 56.0 89.0 67.44
45678.0 86.0 99.0 95.67

```

POI 支持其他更复杂的类和方法来提取数据。

## 处理 PDF 文件

有几个 API 支持从 PDF 文件中提取文本。这里我们将使用 PDFBox。Apache PDF box([https://pdfbox.apache.org/](https://pdfbox.apache.org/))是一个开源 API，允许 Java 程序员处理 PDF 文档。在这一节中，我们将演示如何从 PDF 文档中提取简单的文本。在 https://pdfbox.apache.org/docs/2.0.1/Javadocs/的[可以找到 PDFBox API 的 javadocs。](https://pdfbox.apache.org/docs/2.0.1/javadocs/)

这是一个简单的 PDF 文件。它由几个项目符号组成:

*   第一行
*   第二行
*   第 3 行

这是文件的结尾。

一个`try`块用于抓住`IOExceptions`。`PDDocument`类将代表正在处理的 PDF 文档。它的`load`方法将加载到由`File`对象指定的 PDF 文件中:

```
try { 
    PDDocument document = PDDocument.load(new File("PDF File.pdf")); 
    ... 
} catch (Exception e) { 
    // Handle exceptions 
} 

```

一旦加载完毕，`PDFTextStripper`类`getText`方法将从文件中提取文本。然后显示文本，如下所示:

```
PDFTextStripper Tstripper = new PDFTextStripper(); 
String documentText = Tstripper.getText(document); 
System.out.println(documentText); 

```

该示例的输出如下。请注意，项目符号以问号的形式返回。

```
This is a simple PDF file. It consists of several bullets: 
? Line 1 
? Line 2 
? Line 3 
This is the end of the document.

```

这是对 PDFBox 使用的简单介绍。当我们需要提取和操作 PDF 文档时，它是一个非常强大的工具。

## 处理 JSON

在[第 2 章](part0029.xhtml#aid-RL0A2 "Chapter 2. Data Acquisition")、*数据采集*中，我们了解到某些 YouTube 搜索会返回 JSON 格式的结果。具体来说，`SearchResult`类保存与特定搜索相关的信息。在这一节中，我们说明了如何使用 YouTube 特定的技术来提取信息。在这一节中，我们将说明如何使用 Jackson JSON 实现提取 JSON 信息。

JSON 支持三种数据处理模型:

*   **流 API** -逐令牌处理 JSON 数据
*   **树模型**——JSON 数据完全保存在内存中，然后进行处理
*   **数据绑定**——JSON 数据被转换成 Java 对象

### 使用 JSON 流 API

我们将说明前两种方法。第一种方法效率更高，在处理大量数据时使用。第二种方法很方便，但是数据不能太大。当使用特定的 Java 类处理数据更方便时，第三种技术很有用。例如，如果 JSON 数据代表一个地址，那么可以定义一个特定的 Java 地址类来保存和处理数据。

有几个 Java 库支持 JSON 处理，包括:

*   flex JSON([http://flexjson.sourceforge.net/](http://flexjson.sourceforge.net/))
*   genson([http://owlike . github . io/genson/](http://owlike.github.io/genson/)
*   Google-Gson([https://github.com/google/gson](https://github.com/google/gson))
*   杰克逊图书馆([https://github.com/FasterXML/jackson](https://github.com/FasterXML/jackson))
*   JSON-io(https://github . com/jdereg/JSON-io
*   JSON-lib([http://json-lib.sourceforge.net/](http://json-lib.sourceforge.net/)

我们将使用杰克逊项目([https://github.com/FasterXML/jackson](https://github.com/FasterXML/jackson))。文件可以在 https://github.com/FasterXML/jackson-docs 找到。我们将使用两个 JSON 文件来演示如何使用它。接下来显示的是第一个文件`Person.json`，其中存储了个人数据。它由四个字段组成，其中最后一个字段是位置信息数组。

```
{  
   "firstname":"Smith", 
   "lastname":"Peter",  
   "phone":8475552222, 
   "address":["100 Main Street","Corpus","Oklahoma"]  
} 

```

下面的代码序列显示了如何提取每个字段的值。在 try-catch 块中，创建了一个`JsonFactory`实例，然后基于`Person.json`文件创建了一个`JsonParser`实例。

```
try { 
    JsonFactory jsonfactory = new JsonFactory(); 
    JsonParser parser = jsonfactory.createParser(new File("Person.json")); 
    ... 
    parser.close(); 
} catch (IOException ex) { 
    // Handle exceptions 
} 

```

`nextToken`方法返回一个`token`。然而，`JsonParser`对象跟踪当前的令牌。在`while`循环中，`nextToken`方法返回并让解析器前进到下一个标记。`getCurrentName`方法返回`token`的字段名称。当到达最后一个令牌时,`while`循环终止。

```
while (parser.nextToken() != JsonToken.END_OBJECT) { 
    String token = parser.getCurrentName(); 
    ... 
} 

```

循环体由一系列根据字段名称处理字段的`if`语句组成。由于`address`字段是一个数组，另一个循环将提取它的每个元素，直到到达结束数组`token`。

```
if ("firstname".equals(token)) { 
    parser.nextToken(); 
    String fname = parser.getText(); 
    out.println("firstname : " + fname); 
} 
if ("lastname".equals(token)) { 
    parser.nextToken(); 
    String lname = parser.getText(); 
    out.println("lastname : " + lname); 
} 
if ("phone".equals(token)) { 
    parser.nextToken(); 
    long phone = parser.getLongValue(); 
    out.println("phone : " + phone); 
} 
if ("address".equals(token)) { 
    out.println("address :"); 
    parser.nextToken(); 
    while (parser.nextToken() != JsonToken.END_ARRAY) { 
        out.println(parser.getText()); 
    } 
} 

```

此示例的输出如下:

```
firstname : Smith
lastname : Peter
phone : 8475552222
address :
100 Main Street
Corpus
Oklahoma

```

然而，JSON 对象通常比前一个例子更复杂。这里一个`Persons.json`文件由三个`persons`组成:

```
{ 
   "persons": { 
      "groupname": "school", 
      "person": 
         [  
            {"firstname":"Smith", 
              "lastname":"Peter",  
              "phone":8475552222, 
              "address":["100 Main Street","Corpus","Oklahoma"] }, 
           {"firstname":"King", 
              "lastname":"Sarah",  
              "phone":8475551111, 
              "address":["200 Main Street","Corpus","Oklahoma"] }, 
           {"firstname":"Frost", 
              "lastname":"Nathan",  
              "phone":8475553333, 
              "address":["300 Main Street","Corpus","Oklahoma"] } 
         ] 
   } 
} 

```

为了处理这个文件，我们使用了与前面所示类似的一组代码。我们创建解析器，然后像以前一样进入一个循环:

```
try { 
    JsonFactory jsonfactory = new JsonFactory(); 
    JsonParser parser = jsonfactory.createParser(new File("Person.json")); 
    while (parser.nextToken() != JsonToken.END_OBJECT) { 
        String token = parser.getCurrentName(); 
        ... 
    } 
    parser.close(); 
} catch (IOException ex) { 
    // Handle exceptions 
} 

```

然而，我们需要找到`persons`字段，然后提取它的每个元素。提取并显示`groupname`字段，如下所示:

```
if ("persons".equals(token)) { 
    JsonToken jsonToken = parser.nextToken(); 
    jsonToken = parser.nextToken(); 
    token = parser.getCurrentName(); 
    if ("groupname".equals(token)) { 
        parser.nextToken(); 
        String groupname = parser.getText(); 
        out.println("Group : " + groupname); 
        ... 
    } 
} 

```

接下来，我们找到`person`字段并调用一个`parsePerson`方法来更好地组织代码:

```
parser.nextToken(); 
token = parser.getCurrentName(); 
if ("person".equals(token)) { 
    out.println("Found person"); 
    parsePerson(parser); 
} 

```

接下来的`parsePerson`方法与第一个例子中使用的过程非常相似。

```
public void parsePerson(JsonParser parser) throws IOException { 
    while (parser.nextToken() != JsonToken.END_ARRAY) { 
        String token = parser.getCurrentName(); 
        if ("firstname".equals(token)) { 
            parser.nextToken(); 
            String fname = parser.getText(); 
            out.println("firstname : " + fname); 
        } 
        if ("lastname".equals(token)) { 
            parser.nextToken(); 
            String lname = parser.getText(); 
            out.println("lastname : " + lname); 
        } 
        if ("phone".equals(token)) { 
            parser.nextToken(); 
            long phone = parser.getLongValue(); 
            out.println("phone : " + phone); 
        } 
        if ("address".equals(token)) { 
            out.println("address :"); 
            parser.nextToken(); 
            while (parser.nextToken() != JsonToken.END_ARRAY) { 
                out.println(parser.getText()); 
            } 
        } 
    } 
} 

```

输出如下:

```
Group : school
Found person
firstname : Smith
lastname : Peter
phone : 8475552222
address :
100 Main Street
Corpus
Oklahoma
firstname : King
lastname : Sarah
phone : 8475551111
address :
200 Main Street
Corpus
Oklahoma
firstname : Frost
lastname : Nathan
phone : 8475553333address :
300 Main Street
Corpus
Oklahoma

```

### 使用 JSON 树 API

第二种方法是使用树模型。一个`ObjectMapper`实例用于使用`Persons.json`文件创建一个`JsonNode`实例。`fieldNames`方法返回`Iterator`，允许我们处理文件的每个元素。

```
try { 
    ObjectMapper mapper = new ObjectMapper(); 
    JsonNode node = mapper.readTree(new File("Persons.json")); 
    Iterator<String> fieldNames = node.fieldNames(); 
    while (fieldNames.hasNext()) { 
        ... 
        fieldNames.next(); 
    } 
} catch (IOException ex) { 
    // Handle exceptions 
} 

```

由于 JSON 文件包含一个`persons`字段，我们将获得一个表示该字段的`JsonNode`实例，然后遍历它的每个元素。

```
JsonNode personsNode = node.get("persons"); 
Iterator<JsonNode> elements = personsNode.iterator(); 
while (elements.hasNext()) { 
    ... 
} 

```

一次处理一个元素。如果元素类型是字符串，我们假设这是`groupname`字段。

```
JsonNode element = elements.next(); 
JsonNodeType nodeType = element.getNodeType(); 

if (nodeType == JsonNodeType.STRING) { 
    out.println("Group: " + element.textValue()); 
} 

```

如果元素是一个数组，我们假设它包含一系列人，每个人都由`parsePerson`方法处理:

```
if (nodeType == JsonNodeType.ARRAY) { 
    Iterator<JsonNode> fields = element.iterator(); 
    while (fields.hasNext()) { 
        parsePerson(fields.next()); 
    } 
}
```

`parsePerson`方法如下所示:

```
public void parsePerson(JsonNode node) { 
    Iterator<JsonNode> fields = node.iterator(); 
    while(fields.hasNext()) { 
        JsonNode subNode = fields.next(); 
        out.println(subNode.asText()); 
    } 
}
```

输出如下:

```
Group: school
Smith
Peter
8475552222
King
Sarah
8475551111
Frost
Nathan
8475553333

```

JSON 的内容比我们在这里能够说明的要多得多。但是，这应该会让您了解如何处理这种类型的数据。

# 清理文本的本质

字符串用于支持文本处理，所以使用一个好的字符串库是很重要的。不幸的是，`java.lang.String`类有一些限制。要解决这些限制，您可以根据需要实现自己的特殊字符串函数，也可以使用第三方库。

创建你自己的库是有用的，但是你基本上是在重新发明轮子。编写一个简单的代码序列来实现某些功能可能会更快，但是为了正确地完成任务，您需要对它们进行测试。第三方库已经过测试，并在数百个项目中使用过。它们提供了一种更有效的处理文本的方式。

除了 Java 中的那些之外，还有几个文本处理 API。我们将演示其中的两个:

*   **Apache common**:[https://commons . Apache . org/](https://commons.apache.org/)
*   **番石榴**:【https://github.com/google/guava 

Java 为清理文本数据提供了许多支持，包括`String`类中的方法。这些方法非常适合简单的文本清理和少量数据，但对于较大的复杂数据集也很有效。我们稍后将演示几个`String`类方法。下表总结了一些最有用的`String`类方法:

| **方法名** | **返回类型** | **描述** |
| `trim` | `String` | 删除前导空格和尾随空格 |
| `toUpperCase` / `toLowerCase` | `String` | 更改整个字符串的大小写 |
| `replaceAll` | `String` | 替换字符串中出现的所有字符序列 |
| `contains` | `boolean` | 确定字符串中是否存在给定的字符序列 |
| `compareTo``compareToIgnoreCase` | `int` | 对两个字符串进行词法比较，并返回表示它们之间关系的整数 |
| `matches` | `boolean` | 确定字符串是否与给定的正则表达式匹配 |
| `join` | `String` | 用指定的分隔符组合两个或多个字符串 |
| `split` | `String[]` | 使用指定的分隔符分隔给定字符串的元素 |

正则表达式的使用简化了许多文本操作。正则表达式使用标准化的语法来表示文本中的模式，这可用于定位和操作与模式匹配的文本。

正则表达式本身就是一个字符串。例如，字符串`Hello, my name is Sally`可以用作正则表达式来查找给定文本中的精确单词。这是非常具体的，并不广泛适用，但我们可以使用不同的正则表达式，使我们的代码更有效。`Hello, my name is \\w`将匹配任何以`Hello, my name is`开头并以单词字符结尾的文本。

我们将使用几个更复杂的正则表达式的例子，下表总结了一些更有用的语法选项。注:在 Java 应用程序中使用时，每个都必须双转义。

| **选项** | **描述** |
| `\d` | 任意数字: *0-9* |
| `\D` | 任何非数字 |
| `\s` | 任何空白字符 |
| `\S` | 任何非空白字符 |
| `\w` | 任意单词字符(包括数字): *A-Z* 、 *a-z* 、 *0-9* |
| `\W` | 任何非单词字符 |

文本数据的大小和来源因应用程序而异，但用于转换数据的方法是相同的。你可能真的需要从一个文件中读取数据，但是为了简单起见，我们将使用一个包含赫尔曼·梅尔维尔的《莫比·迪克》开头句子的字符串作为本章的几个例子。除非另有说明，否则将假定文本如下所示:

```
String dirtyText = "Call me Ishmael. Some years ago- never mind how"; 
dirtyText += " long precisely - having little or no money in my purse,"; 
dirtyText += " and nothing particular to interest me on shore, I thought";  
dirtyText += " I would sail about a little and see the watery part of the world."; 

```

## 使用 Java 分词器提取单词

通常，将文本数据作为标记进行分析是最有效的。核心 Java 库中有多个可用的记号赋予器，第三方记号赋予器也是如此。我们将在这一章中演示各种记号化器。理想的记号赋予器将取决于单个应用程序的限制和要求。

### Java 核心令牌化器

是第一个也是最基本的记号赋予器，从 Java 1 开始就有了。不推荐在新的开发中使用，因为`String`类的`split`方法被认为更有效。虽然它确实为具有窄定义和集合分隔符的文件提供了速度优势，但它不如其他记号赋予器选项灵活。下面是一个简单的`StringTokenizer`类的实现，它在空格上分割一个字符串:

```
StringTokenizer tokenizer = new StringTokenizer(dirtyText," "); 
while(tokenizer.hasMoreTokens()){ 
  out.print(tokenizer.nextToken() + " "); 
} 

```

当我们设置`dirtyText`变量来保存来自莫比·迪克的文本时，如前所示，我们得到以下截断的输出:

```
Call me Ishmael. Some years ago- never mind how long precisely...

```

`StreamTokenizer`是另一个核心的 Java 标记器。`StreamTokenizer`提供了更多关于检索到的令牌的信息，并允许用户指定要解析的数据类型，但被认为比`StreamTokenizer`或`split`方法更难使用。`String`类`split`方法是基于分隔符拆分字符串的最简单方法，但是它不提供解析拆分后的字符串的方法，并且您只能为整个字符串指定一个分隔符。由于这些原因，它不是一个真正的记号赋予器，但是它对于数据清理很有用。

`Scanner`类被设计成允许你将字符串解析成不同的数据类型。我们之前在*处理 CSV 数据*部分使用过它，我们将在*移除停用词*部分再次处理它。

### 第三方标记器和库

Apache Commons 由一组开源 Java 类和方法组成。这些提供了补充标准 Java APIs 的可重用代码。公地中包含的一个受欢迎的类是`StrTokenizer`。这个类提供了比标准的`StringTokenizer`类更高级的支持，特别是更多的控制和灵活性。下面是`StrTokenizer`的一个简单实现:

```
StrTokenizer tokenizer = new StrTokenizer(text); 
while (tokenizer.hasNext()) { 
  out.print(tokenizer.next() + " "); 
} 

```

这与`StringTokenizer`的操作方式类似，默认情况下解析空格上的标记。构造函数可以指定分隔符以及如何处理数据中包含的双引号。

当我们使用前面显示的来自莫比·迪克的字符串时，第一个记号赋予器实现产生以下截断的输出:

```
Call me Ishmael. Some years ago- never mind how long precisely - having little or no money in my purse...

```

我们可以如下修改我们的构造函数:

```
StrTokenizer tokenizer = new StrTokenizer(text,","); 

```

该实现的输出是:

```
Call me Ishmael. Some years ago- never mind how long precisely - having little or no money in my purse
and nothing particular to interest me on shore
I thought I would sail about a little and see the watery part of the world.

```

注意每一行是如何在原文中逗号的地方被分割的。这个定界符可以是一个简单的字符，正如我们已经展示的，也可以是一个更复杂的`StrMatcher`对象。

Google Guava 是一组开源的实用 Java 类和方法。与许多 API 一样，Guava 的主要目标是减轻编写基本 Java 实用程序的负担，以便开发人员可以专注于业务流程。我们将在本章中讨论 Guava 中的两个主要工具:`Joiner`类和`Splitter`类。标记化是在 Guava 中使用其`Splitter`类的`split`方法完成的。下面是一个简单的例子:

```
Splitter simpleSplit = Splitter.on(',').omitEmptyStrings().trimResults(); 
Iterable<String> words = simpleSplit.split(dirtyText);  
for(String token: words){ 
  out.print(token); 
} 

```

这会将每个标记用逗号分开，并产生类似于我们上一个示例的输出。我们可以修改`on`方法的参数来分割我们选择的字符。注意 chaining 方法，它允许我们省略空字符串并修剪前导和尾随空格。由于这些原因以及其他高级功能，Google Guava 被一些人认为是 Java 可用的最好的标记器。

**LingPipe** 是一个可用于 Java 语言处理的语言工具包。它通过它的`TokenizerFactory`接口为文本分割提供了更专业的支持。我们在*简单文本清理*部分实现了一个 LingPipe `IndoEuropeanTokenizerFactory`记号化器。

## 将数据转换成可用的形式

一旦获得数据，通常需要对其进行清理。数据集通常不一致，缺少信息，并且包含无关信息。在这一节中，我们将研究一些简单的方法来转换文本数据，使其更有用，更易于分析。

### 简单的文本清理

我们将使用之前显示的来自莫比·迪克的字符串来演示一些基本的`String`类方法。注意`toLowerCase`和`trim`方法的使用。数据集通常有非标准的大小写和额外的前导或尾随空格。这些方法确保了数据集的一致性。我们也使用两次`replaceAll`方法。在第一个实例中，我们使用一个正则表达式用一个空格替换所有数字和任何不是单词或空白字符的内容。第二个实例用一个空格替换所有连续的空白字符:

```
out.println(dirtyText); 
dirtyText =    dirtyText.toLowerCase().replaceAll("[\\d[^\\w\\s]]+", " "); 
dirtyText = dirtyText.trim(); 
while(dirtyText.contains("  ")){ 
  dirtyText = dirtyText.replaceAll("  ", " "); 
} 
out.println(dirtyText);  

```

执行时，代码会产生以下截断的输出:

```
Call me Ishmael. Some years ago- never mind how long precisely -
call me ishmael some years ago never mind how long precisely

```

我们的下一个例子产生了相同的结果，但是用正则表达式解决了这个问题。在这种情况下，我们首先替换所有的数字和其他特殊字符。然后，我们使用方法链接来标准化我们的大小写，删除前导和尾随空格，并将我们的单词拆分到一个`String`数组中。`split`方法允许您在给定的分隔符上拆分文本。在这种情况下，我们选择使用正则表达式`\\W`，它表示任何不是单词字符的东西:

```
out.println(dirtyText); 
dirtyText = dirtyText.replaceAll("[\\d[^\\w\\s]]+", ""); 
String[] cleanText = dirtyText.toLowerCase().trim().split("[\\W]+"); 
for(String clean : cleanText){ 
  out.print(clean + " ");
} 

```

这段代码产生与前面所示相同的输出。

尽管数组对许多应用程序都很有用，但在清理后重新组合文本通常很重要。在下一个例子中，一旦我们清理了单词，我们就使用`join`方法来组合它们。我们使用与前面相同的链接方法来清理和分割我们的文本。`join`方法连接数组`words`中的每个单词，并在每个单词之间插入一个空格:

```
out.println(dirtyText); 
String[] words =    dirtyText.toLowerCase().trim().split("[\\W\\d]+"); 
String cleanText = String.join(" ", words); 
out.println(cleanText); 

```

同样，这段代码产生与前面所示相同的输出。使用谷歌番石榴可以获得另一种版本的`join`方法。下面是我们之前使用的相同过程的一个简单实现，但是使用了 Guava `Joiner`类:

```
out.println(dirtyText);  
String[] words =    dirtyText.toLowerCase().trim().split("[\\W\\d]+"); 
String cleanText = Joiner.on(" ").skipNulls().join(words); 
out.println(cleanText); 

```

这个版本提供了额外的选项，包括跳过空值，如前所示。输出保持不变。

### 删除停用词

文本分析有时需要省略常见的、非特定的单词，如*、*、*和*，或*但*。这些词被称为停用词，有几种工具可以将它们从文本中删除。有各种方法来存储停用词列表，但是对于下面的例子，我们将假设它们包含在一个文件中。首先，我们创建一个新的`Scanner`对象来读取我们的停用词。然后，我们使用`Arrays`类的`asList`方法将我们希望转换的文本存储在`ArrayList`中。这里我们假设文本已经被清理和规范化。在使用`String`类方法时，考虑大小写是很重要的，因为*和*不同于*和*或者*和*，尽管这三个可能都是您希望消除的停用词:

```
Scanner readStop = new Scanner(new File("C://stopwords.txt")); 
ArrayList<String> words = new    ArrayList<String>(Arrays.asList((dirtyText)); 
out.println("Original clean text: " + words.toString()); 

```

我们还创建了一个新的`ArrayList`来保存在我们的文本中实际找到的停用词列表。这将允许我们很快使用`ArrayList`类`removeAll`方法。接下来，我们使用我们的`Scanner`来通读我们的停用词文件。注意我们也是如何针对每个停用词调用`toLowerCase`和`trim`方法的。这是为了确保我们的停用词与文本中的格式相匹配。在这个例子中，我们使用`contains`方法来确定我们的文本是否包含给定的停用词。如果是这样，我们将它添加到我们的`foundWords`数组列表中。一旦我们处理完所有的停用词，我们调用`removeAll`将它们从我们的文本中删除:

```
ArrayList<String> foundWords = new ArrayList(); 
while(readStop.hasNextLine()){ 
  String stopWord = readStop.nextLine().toLowerCase(); 
  if(words.contains(stopWord)){ 
    foundWords.add(stopWord); 
  } 
} 
words.removeAll(foundWords); 
out.println("Text without stop words: " + words.toString()); 

```

输出将取决于被指定为停止字的字。如果停用字词文件包含的字词不同于本示例中使用的字词，则输出会略有不同。我们的输出如下:

```
Original clean text: [call, me, ishmael, some, years, ago, never, mind, how, long, precisely, having, little, or, no, money, in, my, purse, and, nothing, particular, to, interest, me, on, shore, i, thought, i, would, sail, about, a, little, and, see, the, watery, part, of, the, world]
Text without stop words: [call, ishmael, years, ago, never, mind, how, long, precisely

```

标准 Java 库之外也支持删除停用词。我们来看一个例子，使用 LingPipe。在这个例子中，我们首先确保我们的文本被规范化为小写并被修剪。然后我们创建一个`TokenizerFactory`类的新实例。我们将工厂设置为使用默认的英语停用词，然后对文本进行标记。注意，`tokenizer`方法使用了一个`char`数组，所以我们针对我们的文本调用`toCharArray`。第二个参数指定文本中开始搜索的位置，最后一个参数指定结束位置:

```
text = text.toLowerCase().trim(); 
TokenizerFactory fact = IndoEuropeanTokenizerFactory.INSTANCE; 
fact = new EnglishStopTokenizerFactory(fact); 
Tokenizer tok = fact.tokenizer(text.toCharArray(), 0, text.length()); 
for(String word : tok){ 
  out.print(word + " "); 
} 

```

输出如下:

```
Call me Ishmael. Some years ago- never mind how long precisely - having little or no money in my purse, and nothing particular to interest me on shore, I thought I would sail about a little and see the watery part of the world.
call me ishmael . years ago - never mind how long precisely - having little money my purse , nothing particular interest me shore , i thought i sail little see watery part world .

```

请注意我们之前的例子之间的差异。首先，我们没有彻底清理文本，并允许特殊字符(如连字符)保留在文本中。其次，LingPipe 的停用词列表不同于我们在前面的例子中使用的文件。一些单词被删除了，但是 LingPipe 限制更少，允许更多的单词保留在文本中。您使用的停用字词的类型和数量将取决于您的特定应用。

## 在文本中查找单词

标准 Java 库支持在文本中搜索特定的标记。在前面的例子中，我们已经演示了`matches`方法和正则表达式，它们在搜索文本时会很有用。然而，在这个例子中，我们将演示一个简单的技术，使用`contains`方法和`equals`方法来定位一个特定的字符串。首先，我们规范化我们的文本和我们正在搜索的单词，以确保我们可以找到匹配。我们还创建了一个整数变量来保存单词被找到的次数:

```
dirtyText = dirtyText.toLowerCase().trim(); 
toFind = toFind.toLowerCase().trim(); 
int count = 0; 

```

接下来，我们调用`contains`方法来确定这个单词是否存在于我们的文本中。如果是，我们将文本分割成一个数组，然后循环遍历，使用`equals`方法来比较每个单词。如果我们遇到这个单词，我们就把计数器加 1。最后，我们显示输出，以显示我们的单词被遇到的次数:

```

if(dirtyText.contains(toFind)){ 
      String[] words = dirtyText.split(" "); 
      for(String word : words){ 
            if(word.equals(toFind)){ 
                  count++; 
            } 
      } 
out.println("Found " + toFind + " " + count + " times in the text."); 
} 

```

在这个例子中，我们将`toFind`设置为字母`I`。这产生了以下输出:

```
Found i 2 times in the text.

```

我们还可以选择使用`Scanner`类来搜索整个文件。一个有用的方法是`findWithinHorizon`方法。这使用了一个`Scanner`来解析文本直到一个给定的 horizon 规范。如果第二个参数为 0，如下所示，默认情况下将搜索整个`Scanner`:

```
dirtyText = dirtyText.toLowerCase().trim();  
toFind = toFind.toLowerCase().trim(); 
Scanner textLine = new Scanner(dirtyText); 
out.println("Found " + textLine.findWithinHorizon(toFind, 10)); 

```

这种技术可以更有效地定位特定的字符串，但它确实使确定在哪里找到该字符串以及找到该字符串的次数变得更加困难。

使用`BufferedReader`搜索整个文件也会更有效。我们指定要搜索的文件，并使用 try-catch 块来捕获任何 IO 异常。我们从我们的路径创建一个新的`BufferedReader`对象，只要下一行不为空，就处理我们的文件:

```
String path = "C:// MobyDick.txt"; 
try { 
    String textLine = ""; 
    toFind = toFind.toLowerCase().trim(); 
    BufferedReader textToClean = new BufferedReader( 
        new FileReader(path)); 
    while((textLine = textToClean.readLine()) != null){ 
        line++; 
        if(textLine.toLowerCase().trim().contains(toFind)){ 
            out.println("Found " + toFind + " in " + textLine); 
           } 
    } 
    textToClean.close(); 
} catch (IOException ex) { 
    // Handle exceptions 
} 

```

我们再次通过在莫比·迪克的第一句话中搜索单词`I`来测试我们的数据。截断的输出如下:

```
Found i in Call me Ishmael...

```

### 查找和替换文本

我们经常不仅想找到文本，还想用其他东西替换它。我们开始下一个例子，就像我们之前的例子一样，通过指定我们的文本，我们要定位的文本，并调用`contains`方法。如果我们找到了文本，我们调用`replaceAll`方法来修改我们的字符串:

```
text = text.toLowerCase().trim(); 
toFind = toFind.toLowerCase().trim(); 
out.println(text); 

if(text.contains(toFind)){ 
      text = text.replaceAll(toFind, replaceWith); 
      out.println(text); 
} 

```

为了测试这段代码，我们将`toFind`设置为单词`I`，将`replaceWith`设置为`Ishmael`。我们的输出如下:

```
call me ishmael. some years ago- never mind how long precisely - having little or no money in my purse, and nothing particular to interest me on shore, i thought i would sail about a little and see the watery part of the world.
call me ishmael. some years ago- never mind how long precisely - having little or no money in my purse, and nothing particular to interest me on shore, Ishmael thought Ishmael would sail about a little and see the watery part of the world.

```

Apache Commons 还提供了一个在`StringUtils`类中有几个变体的`replace`方法。这个类提供了与`String`类相同的功能，但是有更多的灵活性和选项。在下面的例子中，我们使用来自莫比·迪克的字符串，将单词`me`的所有实例替换为`X`来演示`replace`方法:

```
out.println(text); 
out.println(StringUtils.replace(text, "me", "X")); 

```

截断的输出如下:

```
Call me Ishmael. Some years ago- never mind how long precisely -
Call X Ishmael. SoX years ago- never mind how long precisely -

```

请注意`me`的每个实例是如何被替换的，甚至是那些包含在其他单词中的实例，例如`some.`这可以通过在`me`周围添加空格来避免，尽管这将忽略任何 me 位于句子末尾的实例，例如 me。我们将在一会儿用谷歌番石榴检查一个更好的选择。

`StringUtils`类还提供了一个`replacePattern`方法，允许您基于正则表达式搜索和替换文本。在以下示例中，我们用一个空格替换所有非单词字符，如连字符和逗号:

```
out.println(text); 
text = StringUtils.replacePattern(text, "\\W\\s", " "); 
out.println(text); 

```

这将产生以下截断的输出:

```
Call me Ishmael. Some years ago- never mind how long precisely - 
Call me Ishmael Some years ago never mind how long precisely

```

Google Guava 使用`CharMatcher`类为匹配和修改文本数据提供了额外的支持。`CharMatcher`不仅允许您查找匹配特定字符模式的数据，还提供了如何处理数据的选项。这包括允许您保留数据、替换数据以及从特定字符串中修剪空白。

在这个例子中，我们将使用`replace`方法简单地用一个空格替换单词`me`的所有实例。这将在我们的文本中产生一系列的空白。然后，我们将使用`trimAndCollapseFrom`方法折叠多余的空格，并再次打印我们的字符串:

```
text = text.replace("me", " "); 
out.println("With double spaces: " + text); 
String spaced = CharMatcher.WHITESPACE.trimAndCollapseFrom(text, ' '); 
out.println("With double spaces removed: " + spaced); 

```

我们的输出被截断如下:

```
With double spaces: Call Ishmael. So years ago- ...
With double spaces removed: Call Ishmael. So years ago- ...

```

## 数据插补

数据插补是指识别和替换给定数据集中缺失数据的过程。在几乎所有的数据分析案例中，缺失数据都是一个问题，需要在正确分析数据之前解决这个问题。试图处理缺失信息的数据就像试图理解一场偶尔会漏掉一个词的对话。有时我们能理解意图是什么。在其他情况下，我们可能完全不知道想要传达什么。

在统计分析人员中，对于如何处理缺失数据存在不同意见，但最常见的方法是用合理的估计值或空值替换缺失数据。

为了防止数据偏斜和错位，许多统计学家主张用代表该数据集平均值或期望值的值来替换缺失的数据。确定代表值并将其分配到数据中某个位置的方法会因数据而异，我们无法在本章中一一举例说明。但是，例如，如果数据集包含某个日期范围内的温度列表，并且某个日期缺少温度，则可以为该日期指定一个温度，该温度是数据集内温度的平均值。

我们将研究一个相当琐碎的例子来说明围绕数据插补的问题。让我们假设变量`tempList`包含一年中每个月的平均温度数据。然后，我们执行简单的平均值计算，并打印出结果:

```
   double[] tempList = {50,56,65,70,74,80,82,90,83,78,64,52}; 
   double sum = 0; 
   for(double d : tempList){ 
         sum += d; 
   } 
   out.printf("The average temperature is %1$,.2f", sum/12); 

```

请注意，对于该执行中使用的数字，输出如下:

```
The average temperature is 70.33

```

接下来，在计算我们的`sum`之前，我们将通过将数组的第一个元素更改为零来模拟缺失数据:

```
   double sum = 0; 
   tempList[0] = 0; 
   for(double d : tempList){ 
         sum += d; 
   } 
   out.printf("The average temperature is %1$,.2f", sum/12); 

```

这将改变我们输出中显示的平均温度:

```
The average temperature is 66.17

```

请注意，虽然这种变化看起来很小，但在统计上却很重要。根据给定数据集内的变化以及平均值与零或其他替代值的差距，统计分析的结果可能会有很大偏差。这并不意味着不应该用零来代替空值或其他无效值，而是应该考虑其他替代值。

一种替代方法是计算数组中值的平均值，排除零或空值，然后用缺失数据替换每个位置的平均值。在做出这些决定时，考虑数据的类型和数据分析的目的是很重要的。例如，在前面的例子中，零是否总是无效的平均温度？如果南极洲的温度是平均的，也许不会。

当需要处理空数据时，Java 的`Optional`类提供了有用的解决方案。考虑下面的例子，我们有一个以数组形式存储的名字列表。为了演示这些方法，我们给`null`设置了一个值:

```
   String useName = ""; 
   String[] nameList =
         {"Amy","Bob","Sally","Sue","Don","Rick",null,"Betsy"}; 
   Optional<String> tempName; 
   for(String name : nameList){ 
         tempName = Optional.ofNullable(name); 
         useName = tempName.orElse("DEFAULT"); 
         out.println("Name to use = " + useName); 
   } 

```

我们首先创建了一个名为`useName`的变量来保存我们将实际打印出来的名称。我们还创建了一个名为`tempName`的`Optional`类的实例。我们将用它来测试数组中的值是否为空。然后我们遍历数组，创建并调用`Optional`类`ofNullable`方法。这个方法测试一个特定的值是否为空。在下一行，我们调用`orElse`方法将数组中的一个值赋给`useName`，或者如果元素为空，则赋给`DEFAULT`。我们的输出如下:

```
Name to use = Amy
Name to use = Bob
Name to use = Sally
Name to use = Sue
Name to use = Don
Name to use = Rick
Name to use = DEFAULT
Name to use = Betsy

```

`Optional`类包含其他几个用于处理潜在空数据的方法。尽管有其他方法来处理这样的实例，但是 Java 8 的这一新增功能为常见的数据分析问题提供了更简单、更优雅的解决方案。

## 子集化数据

处理一整套数据并不总是实际可行的，也不总是可取的。在这些情况下，我们可能希望检索数据的子集，以便处理或从数据集中完全删除。标准 Java 库支持几种方法。首先，我们将使用`SortedSet`接口的`subSet`方法。我们将从在一个`TreeSet`中存储一个数字列表开始。然后我们创建一个新的`TreeSet`对象来保存从列表中检索到的子集。接下来，我们打印出原始列表:

```
Integer[] nums = {12, 46, 52, 34, 87, 123, 14, 44}; 
TreeSet<Integer> fullNumsList = new TreeSet<Integer>(new 
ArrayList<>(Arrays.asList(nums))); 
SortedSet<Integer> partNumsList; 
out.println("Original List: " + fullNumsList.toString()  
    + " " + fullNumsList.last()); 

```

`subSet`方法有两个参数，它们指定了我们想要检索的数据中的整数范围。第一个参数包含在结果中，而第二个参数是唯一的。在下面的例子中，我们希望检索数组中第一个数字`12`和`46`之间所有数字的子集:

```

partNumsList = fullNumsList.subSet(fullNumsList.first(), 46); 
out.println("SubSet of List: " + partNumsList.toString()  
    + " " + partNumsList.size());       

```

我们的输出如下:

```
Original List: [12, 14, 34, 44, 46, 52, 87, 123] 
SubSet of List: [12, 14, 34, 44]

```

另一种选择是结合使用`stream`方法和`skip`方法。`stream`方法返回一个 Java 8 流实例，该实例对集合进行迭代。我们将使用与上一个例子相同的`numsList`，但是这一次我们将使用`skip`方法指定跳过多少个元素。我们还将使用`collect`方法创建一个新的`Set`来保存新元素:

```
out.println("Original List: " + numsList.toString()); 
Set<Integer> fullNumsList = new TreeSet<Integer>(numsList); 
Set<Integer> partNumsList = fullNumsList 
         .stream() 
         .skip(5) 
         .collect(toCollection(TreeSet::new)); 
out.println("SubSet of List: " + partNumsList.toString());  

```

当我们打印出新的子集时，我们得到下面的输出，其中跳过了排序集的前五个元素。因为它是一个`SortedSet`，我们实际上将省略五个最低的数字:

```
Original List: [12, 46, 52, 34, 87, 123, 14, 44]
SubSet of List: [52, 87, 123]

```

有时，数据会以空行或标题行开始，我们希望从要分析的数据集中删除这些空行或标题行。在我们的最后一个例子中，我们将从文件中读取数据并删除所有的空行。我们使用一个`BufferedReader`来读取数据，并使用一个 lambda 表达式来测试空行。如果该行不为空，我们将该行打印到屏幕上:

```
try (BufferedReader br = new BufferedReader(new FileReader("C:\\text.txt"))) { 
   br 
         .lines() 
         .filter(s -> !s.equals("")) 
         .forEach(s -> out.println(s)); 
} catch (IOException ex) { 
   // Handle exceptions 
} 

```

## 排序文本

有时候在清理过程中需要对数据进行排序。标准 Java 库为完成不同类型的排序提供了一些资源，Java 8 的发布增加了一些改进。在我们的第一个例子中，我们将结合 lambda 表达式使用`Comparator`接口。

我们从声明变量`compareInts`开始。等号后面的第一组括号包含要传递给我们的方法的参数。在 lambda 表达式中，我们调用`compare`方法，它决定哪个整数更大:

```
 Comparator<Integer> compareInts = (Integer first, Integer second) ->
   Integer.compare(first, second); 

```

我们现在可以像以前一样调用`sort`方法:

```

Collections.sort(numsList,compareInts); 
out.println("Sorted integers using Lambda: " + numsList.toString()); 

```

我们的输出如下:

```
Sorted integers using Lambda: [12, 14, 34, 44, 46, 52, 87, 123]

```

然后我们用`wordsList`模拟这个过程。注意使用了`compareTo`方法，而不是`compare`:

```

Comparator<String> compareWords = (String first, String second) -> first.compareTo(second); 
Collections.sort(wordsList,compareWords); 
out.println("Sorted words using Lambda: " + wordsList.toString()); 

```

当执行这段代码时，我们应该会看到以下输出:

```
Sorted words using Lambda: [boat, cat, dog, house, road, zoo]

```

在下一个例子中，我们将使用`Collections`类对`String`和整数数据进行基本排序。在本例中，`wordList`和`numsList`都是`ArrayList`，初始化如下:

```
List<String> wordsList 
        = Stream.of("cat", "dog", "house", "boat", "road", "zoo") 
        .collect(Collectors.toList()); 
List<Integer> numsList = Stream.of(12, 46, 52, 34, 87, 123, 14, 44) 
        .collect(Collectors.toList()); 

```

首先，我们将打印每个列表的原始版本，然后调用`sort`方法。然后我们显示我们的数据，按升序排列:

```
out.println("Original Word List: " + wordsList.toString()); 
Collections.sort(wordsList); 
out.println("Ascending Word List: " + wordsList.toString()); 
out.println("Original Integer List: " + numsList.toString()); 
Collections.sort(numsList); 
out.println("Ascending Integer List: " + numsList.toString()); 

```

输出如下:

```
Original Word List: [cat, dog, house, boat, road, zoo]
Ascending Word List: [boat, cat, dog, house, road, zoo]
Original Integer List: [12, 46, 52, 34, 87, 123, 14, 44]
Ascending Integer List: [12, 14, 34, 44, 46, 52, 87, 123]

```

接下来，我们将在整数数据示例中用`Collections`类的`reverse`方法替换`sort`方法。这个方法简单地获取元素并以相反的顺序存储它们:

```
 out.println("Original Integer List: " + numsList.toString()); 
 Collections.reverse(numsList); 
 out.println("Reversed Integer List: " + numsList.toString()); 

```

输出显示我们新的`numsList`:

```
Original Integer List: [12, 46, 52, 34, 87, 123, 14, 44]
Reversed Integer List: [44, 14, 123, 87, 34, 52, 46, 12]

```

在下一个例子中，我们使用`Comparator`接口来处理排序。我们将继续使用我们的`numsList`,并假设排序还没有发生。首先我们创建两个实现`Comparator`接口的对象。`sort`方法将在比较两个元素时使用这些对象来确定所需的顺序。表达式`Integer::compare`是一个 Java 8 方法引用。这可用于使用 lambda 表达式的情况:

```
out.println("Original Integer List: " + numsList.toString()); 
Comparator<Integer> basicOrder = Integer::compare; 
Comparator<Integer> descendOrder = basicOrder.reversed(); 
Collections.sort(numsList,descendOrder); 
out.println("Descending Integer List: " + numsList.toString()); 

```

执行这段代码后，我们将看到以下输出:

```
Original Integer List: [12, 46, 52, 34, 87, 123, 14, 44]
Descending Integer List: [123, 87, 52, 46, 44, 34, 14, 12]

```

在最后一个例子中，我们将尝试一个更复杂的排序，包括两个比较。让我们假设有一个包含两个属性`name`和`age`的`Dog`类，以及必要的访问方法。我们将开始向一个新的`ArrayList`添加元素，然后打印每个`Dog`的名字和年龄:

```

ArrayList<Dogs> dogs = new ArrayList<Dogs>(); 
dogs.add(new Dogs("Zoey", 8)); 
dogs.add(new Dogs("Roxie", 10)); 
dogs.add(new Dogs("Kylie", 7)); 
dogs.add(new Dogs("Shorty", 14)); 
dogs.add(new Dogs("Ginger", 7)); 
dogs.add(new Dogs("Penny", 7)); 
out.println("Name " + " Age"); 
for(Dogs d : dogs){ 
      out.println(d.getName() + " " + d.getAge()); 
} 

```

我们的输出应该类似于:

```
Name Age
Zoey 8
Roxie 10
Kylie 7
Shorty 14
Ginger 7
Penny 7

```

接下来，我们将使用方法链接和双冒号操作符来引用来自`Dog`类的方法。我们首先调用`comparing`,然后调用`thenComparing`,以指定比较发生的顺序。当我们执行代码时，我们希望看到`Dog`对象首先按照`Name`排序，然后按照`Age`排序:

```
      dogs.sort(Comparator.comparing(Dogs::getName).thenComparing(Dogs::getAge)); 
out.println("Name " + " Age"); 
for(Dogs d : dogs){ 
      out.println(d.getName() + " " + d.getAge()); 
} 

```

我们的输出如下:

```
Name Age
Ginger 7
Kylie 7
Penny 7
Roxie 10
Shorty 14
Zoey 8

```

现在我们将交换比较的顺序。请注意，在这个版本中，狗的年龄优先于名字:

```
   dogs.sort(Comparator.comparing(Dogs::getAge).thenComparing(Dogs::getName)); 
out.println("Name " + " Age"); 
for(Dogs d : dogs){ 
      out.println(d.getName() + " " + d.getAge()); 
} 

```

我们的输出是:

```
Name Age
Ginger 7
Kylie 7
Penny 7
Zoey 8
Roxie 10
Shorty 14

```

## 数据验证

数据验证是数据科学的重要组成部分。在我们能够分析和操作数据之前，我们需要验证数据是预期的类型。我们已经将代码组织成简单的方法，用于完成非常基本的验证任务。这些方法中的代码可以适用于现有的应用程序。

### 验证数据类型

有时我们只需要验证一段数据是否属于特定类型，比如整数或浮点数据。我们将在下一个例子中演示如何使用`validateIn` t 方法验证整数数据。对于标准 Java 库中支持的其他主要数据类型，包括`Float`和`Double`，这种技术很容易修改。

我们需要在这里使用一个 try-catch 块来捕捉一个`NumberFormatException`。如果抛出异常，我们知道我们的数据不是有效的整数。我们首先将待测试的文本传递给`Integer`类的`parseInt`方法。如果文本可以被解析为一个整数，我们只需打印出这个整数。如果抛出一个异常，我们会显示相应的信息:

```
public static void validateInt(String toValidate){ 
try{ 
      int validInt = Integer.parseInt(toValidate); 
      out.println(validInt + " is a valid integer"); 
}catch(NumberFormatException e){ 
      out.println(toValidate + " is not a valid integer"); 

} 

```

我们将使用以下方法调用来测试我们的方法:

```
validateInt("1234"); 
validateInt("Ishmael"); 

```

输出如下:

```
1234 is a valid integer
Ishmael is not a valid integer

```

Apache Commons 包含一个具有额外有用功能的`IntegerValidator`类。在第一个例子中，我们简单地重复之前的过程，但是使用`IntegerValidator`方法来实现我们的目标:

```
public static String validateInt(String text){ 
      IntegerValidator intValidator = IntegerValidator.getInstance(); 
      if(intValidator.isValid(text)){ 
            return text + " is a valid integer"; 
      }else{ 
            return text + " is not a valid integer"; 
      }      
} 

```

我们再次使用下面的方法调用来测试我们的方法:

```
validateInt("1234"); 
validateInt("Ishmael"); 

```

输出如下:

```
1234 is a valid integer
Ishmael is not a valid integer

```

`IntegerValidator`类还提供了一些方法来确定一个整数是大于还是小于一个特定值，将该数字与一组数字进行比较，并将`Number`对象转换为`Integer`对象。Apache Commons 有许多其他的验证器类。我们将在本节的剩余部分研究更多的内容。

### 验证日期

很多时候，我们的数据验证比简单地确定一段数据是否是正确的类型更复杂。例如，当我们想要验证数据是一个日期时，仅仅验证它是由整数组成的是不够的。我们可能需要包括连字符和斜线，或者确保年份是两位数或四位数的格式。

为此，我们创建了另一个简单的方法`validateDate`。该方法有两个`String`参数，一个保存要验证的日期，另一个保存可接受的日期格式。我们使用参数中指定的格式创建了一个`SimpleDateFormat`类的实例。然后我们调用`parse`方法将我们的`String`日期转换成一个`Date`对象。就像我们前面的整数示例一样，如果数据不能被解析为日期，就会抛出一个异常，方法返回。但是，如果可以将`String`解析为日期，我们只需将测试日期的格式与我们可接受的格式进行比较，以确定日期是否有效:

```

public static String validateDate(String theDate, String dateFormat){ 
      try { 
            SimpleDateFormat format = new SimpleDateFormat(dateFormat); 
            Date test = format.parse(theDate); 
            if(format.format(test).equals(theDate)){ 
                  return theDate.toString() + " is a valid date"; 
            }else{ 
                  return theDate.toString() + " is not a valid date"; 
            } 
      } catch (ParseException e) { 
            return theDate.toString() + " is not a valid date"; 
      } 
} 

```

我们进行以下方法调用来测试我们的方法:

```
String dateFormat = "MM/dd/yyyy"; 
out.println(validateDate("12/12/1982",dateFormat)); 
out.println(validateDate("12/12/82",dateFormat)); 
out.println(validateDate("Ishmael",dateFormat)); 

```

输出如下:

```
12/12/1982 is a valid date
12/12/82 is not a valid date
Ishmael is not a valid date

```

这个例子强调了考虑对数据的限制的重要性。我们的第二个方法调用包含一个合法的日期，但是它不是我们指定的格式。如果我们正在寻找非常特殊格式的数据，这是很好的。但是，如果我们在验证中过于严格，我们也有遗漏有用数据的风险。

### 验证电子邮件地址

还经常需要验证电子邮件地址。虽然大多数电子邮件地址都有`@`符号，并要求符号后至少有一个句点，但也有许多变体。请考虑以下每个示例都可以是有效的电子邮件地址:

*   `myemail@mail.com`
*   `MyEmail@some.mail.com`
*   `My.Email.123!@mail.net`

一种选择是使用正则表达式来尝试捕获所有允许的电子邮件地址。请注意，下面的方法中使用的正则表达式非常长且复杂。这很容易出错，错过有效的电子邮件地址，或者将无效地址视为有效地址。但是一个精心制作的正则表达式可能是一个非常强大的工具。

我们使用`Pattern`和`Matcher`类来编译和执行我们的正则表达式。如果我们传入的电子邮件模式与我们定义的正则表达式匹配，我们将认为该文本是有效的电子邮件地址:

```
public static String validateEmail(String email) { 
      String emailRegex = "^[a-zA-Z0-9.!$'*+/=?^_`{|}~-" +
          "]+@((\\[[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\." + 
          "[0-9]{1,3}\\])|(([a-zAZ\\-0-9]+\\.)+[a-zA-Z]{2,}))$"; 
      Pattern.compile(emailRegex); 
      Matcher matcher = pattern.matcher(email); 
      if(matcher.matches()){ 
            return email + " is a valid email address"; 
      }else{ 
            return email + " is not a valid email address"; 
      } 
} 

```

我们调用以下方法来测试我们的数据:

```
out.println(validateEmail("myemail@mail.com")); 
out.println(validateEmail("My.Email.123!@mail.net")); 
out.println(validateEmail("myEmail")); 

```

输出如下:

```
myemail@mail.com is a valid email address
My.Email.123!@mail.net is a valid email address
myEmail is not a valid email address

```

还有一个用于验证电子邮件地址的标准 Java 库。在这个例子中，我们使用`InternetAddress`类来验证给定的字符串是否是有效的电子邮件地址:

```
    public static String validateEmailStandard(String email){ 
        try{ 
            InternetAddress testEmail = new InternetAddress(email); 
            testEmail.validate(); 
            return email + " is a valid email address"; 
        }catch(AddressException e){ 
            return email + " is not a valid email address"; 
        } 
    } 

```

当使用与上例相同的数据进行测试时，我们的输出是相同的。但是，请考虑下面的方法调用:

```
    out.println(validateEmailStandard("myEmail@mail")); 

```

尽管不是标准的电子邮件格式，但输出如下:

```
myEmail@mail is a valid email address

```

此外，`validate`方法默认接受本地电子邮件地址作为有效地址。根据数据的用途，这并不总是可取的。

我们要看的最后一个选项是 Apache Commons `EmailValidator`类。这个类的`isValid`方法检查一个电子邮件地址，并确定它是否有效。我们之前展示的`validateEmail`方法修改如下以使用`EmailValidator`:

```
public static String validateEmailApache(String email){ 
      email = email.trim(); 
      EmailValidator eValidator = EmailValidator.getInstance(); 
      if(eValidator.isValid(email)){ 
            return email + " is a valid email address."; 
      }else{ 
            return email + " is not a valid email address."; 
      } 
} 

```

### 验证邮政编码

邮政编码通常根据其所在国家或当地的要求进行格式化。因此，正则表达式非常有用，因为它们可以适应任何所需的邮政编码。下面的示例演示了如何验证标准的美国邮政编码，包括或不包括连字符和最后四位数字:

```
public static void validateZip(String zip){ 
      String zipRegex = "^[0-9]{5}(?:-[0-9]{4})?$"; 
      Pattern pattern = Pattern.compile(zipRegex); 
      Matcher matcher = pattern.matcher(zip); 
      if(matcher.matches()){ 
            out.println(zip + " is a valid zip code"); 
      }else{ 
            out.println(zip + " is not a valid zip code"); 
      } 
} 

```

我们调用以下方法来测试我们的数据:

```
out.println(validateZip("12345")); 
out.println(validateZip("12345-6789")); 
out.println(validateZip("123")); 

```

输出如下:

```
12345 is a valid zip code
12345-6789 is a valid zip code
123 is not a valid zip code

```

### 验证姓名

名称可能特别难以验证，因为有太多的变体。除了键盘上可用的字符之外，没有行业标准或技术限制。对于这个例子，我们选择在正则表达式中使用 Unicode，因为它允许我们匹配任何语言的任何字符。Unicode 属性`\\p{L}`提供了这种灵活性。我们还使用 `\\s-'`，允许名称字段中有空格、撇号、逗号和连字符。在尝试匹配名称之前，可以执行字符串清理，如本章前面所讨论的。这将简化所需的正则表达式:

```
public static void validateName(String name){ 
      String nameRegex = "^[\\p{L}\\s-',]+$"; 
      Pattern pattern = Pattern.compile(nameRegex); 
      Matcher matcher = pattern.matcher(name); 
      if(matcher.matches()){ 
            out.println(name + " is a valid name"); 
      }else{ 
            out.println(name + " is not a valid name"); 
      } 
} 

```

我们调用以下方法来测试我们的数据:

```
validateName("Bobby Smith, Jr."); 
validateName("Bobby Smith the 4th"); 
validateName("Albrecht Müller"); 
validateName("François Moreau"); 

```

输出如下:

```
Bobby Smith, Jr. is a valid name
Bobby Smith the 4th is not a valid name
Albrecht Müller is a valid name
François Moreau is a valid name

```

注意，`Bobby Smith, Jr.`中的逗号和句号是可以接受的，但是`4th`中的`4`是不可以接受的。另外，`François`和`Müller`中的特殊字符被认为是有效的。

# 清洗图像

虽然图像处理是一项复杂的任务，我们将介绍一些技术来清理和提取图像中的信息。这将使读者对图像处理有所了解。我们还将演示如何使用**光学字符识别(OCR)从图像中提取文本数据。**

有几种技术可用于提高图像质量。其中许多需要调整参数来获得期望的改善。我们将演示如何:

*   增强图像的对比度
*   平滑图像
*   使图像变亮

*   调整图像大小
*   将图像转换为不同的格式

我们将使用 OpenCV([http://opencv.org/](http://opencv.org/))，一个用于图像处理的开源项目。我们将使用几个类:

*   `Mat`:这是一个保存图像数据的 n 维数组，比如通道、灰度或颜色值
*   拥有许多处理图像的方法
*   `Imgcodecs`:拥有读写图像文件的方法

OpenCV Javadocs 位于[http://docs.opencv.org/java/2.4.9/](http://docs.opencv.org/java/2.4.9/)。在下面的例子中，我们将使用维基百科的图片，因为它们可以免费下载。具体来说，我们将使用以下图像:

*   **鹦鹉图片**:[https://en . Wikipedia . org/wiki/gray #/media/File:gray _ 8 bits _ palette _ sample _ image . png](https://en.wikipedia.org/wiki/Grayscale)
*   **猫咪形象**:[https://en . Wikipedia . org/wiki/Cat #/media/File:kitty ply _ edit 1 . jpg](https://en.wikipedia.org/wiki/Cat#/media/File:Kittyply_edit1.jpg)

## 改变图像的对比度

这里我们将演示如何增强鹦鹉的黑白图像。`Imgcodecs`类的`imread`方法读入图像。它的第二个参数指定图像使用的颜色类型，在本例中是灰度。使用与原始图像相同的大小和颜色类型为增强图像创建一个新的`Mat`对象。

实际工作由`equalizeHist`方法执行。这均衡了图像的直方图，具有归一化亮度的效果，并增加了图像的对比度。图像直方图是表示图像色调分布的直方图。**色调**又称明度。它表示图像中亮度的变化。

最后一步是写出图像。

```
Mat source = Imgcodecs.imread("GrayScaleParrot.png", 
        Imgcodecs.CV_LOAD_IMAGE_GRAYSCALE); 
Mat destination = new Mat(source.rows(), source.cols(), source.type()); 
Imgproc.equalizeHist(source, destination); 
Imgcodecs.imwrite("enhancedParrot.jpg", destination); 

```

以下是原图:

![Changing the contrast of an image](img/image00274.jpeg)

增强图像如下:

![Changing the contrast of an image](img/image00275.jpeg)

## 平滑图像

平滑图像，也称为**模糊**，会使图像的边缘更加平滑。模糊是使图像变得不那么清晰的过程。当我们在相机失焦的情况下拍照时，我们能识别模糊的物体。模糊可以用于特殊效果。在这里，我们将使用它来创建一个图像，然后我们将锐化。

下面的示例加载一幅猫的图像，并对该图像重复应用`blur`方法。在该示例中，该过程重复了`25`次。增加迭代次数将导致更多的模糊或平滑。

模糊方法的第三个参数是模糊核的大小。内核是一个像素矩阵，在本例中为 3×3，用于卷积。这是将图像的每个元素乘以其邻居的加权值的过程。这允许相邻值影响元素的值:

```
Mat source = Imgcodecs.imread("cat.jpg"); 
Mat destination = source.clone(); 
for (int i = 0; i < 25; i++) { 
    Mat sourceImage = destination.clone(); 
    Imgproc.blur(sourceImage, destination, new Size(3.0, 3.0)); 
} 
Imgcodecs.imwrite("smoothCat.jpg", destination); 

```

以下是原图:

![Smoothing an image](img/image00276.jpeg)

增强图像如下:

![Smoothing an image](img/image00277.jpeg)

## 使图像变亮

`convertTo`方法提供了一种使图像变亮的方法。原始图像被复制到新图像，在新图像中对比度和亮度被调整。第一个参数是目标图像。第二个指定不应该更改图像的类型。第三和第四个参数分别控制对比度和亮度。第一个值与此值相乘，第二个值与相乘后的值相加:

```
Mat source = Imgcodecs.imread("cat.jpg"); 
Mat destination = new Mat(source.rows(), source.cols(), 
        source.type()); 
source.convertTo(destination, -1, 1, 50); 
Imgcodecs.imwrite("brighterCat.jpg", destination); 

```

增强图像如下:

![Brightening an image](img/image00278.jpeg)

## 调整图像大小

有时需要调整图像的大小。接下来显示的`resize`方法说明了这是如何实现的。读入图像并创建一个新的`Mat`对象。然后应用`resize`方法，在`Size`对象参数中指定宽度和高度。然后保存调整后的图像:

```
Mat source = Imgcodecs.imread("cat.jpg"); 
Mat resizeimage = new Mat(); 
Imgproc.resize(source, resizeimage, new Size(250, 250)); 
Imgcodecs.imwrite("resizedCat.jpg", resizeimage); 

```

增强图像如下:

![Resizing an image](img/image00279.jpeg)

## 将图像转换成不同的格式

另一个常见的操作是将使用一种格式的图像转换为使用不同格式的图像。在 OpenCV 中，这很容易实现，如下所示。图像被读入，然后立即被写出。`imwrite`方法使用文件的扩展名将图像转换成新格式:

```
Mat source = Imgcodecs.imread("cat.jpg"); 
Imgcodecs.imwrite("convertedCat.jpg", source); 
Imgcodecs.imwrite("convertedCat.jpeg", source); 
Imgcodecs.imwrite("convertedCat.webp", source); 
Imgcodecs.imwrite("convertedCat.png", source); 
Imgcodecs.imwrite("convertedCat.tiff", source); 

```

如果需要，这些图像现在可以用于专门的处理。



# 总结

很多时候，数据科学中一半的战斗是操纵数据，使它足够干净，可以使用。在这一章中，我们考察了许多获取真实世界中杂乱数据并将其转换成可用数据集的技术。这个过程通常被称为数据清理、争论、整形或蒙戈。我们的重点是核心 Java 技术，但是我们也研究了第三方库。

在清理数据之前，我们需要对数据的格式有一个坚实的理解。我们讨论了 CSV 数据、电子表格、PDF 和 JSON 文件类型，并提供了几个操作文本文件数据的例子。当我们检查文本数据时，我们查看了处理数据的多种方法，包括标记化器、`Scanners`和`BufferedReaders`。我们展示了执行简单清理操作、删除停用词以及执行查找和替换功能的方法。

本章还讨论了数据估算以及确定和纠正缺失数据情况的重要性。缺失数据会在数据分析过程中引起问题，我们提出了不同的方法来处理这个问题。我们演示了如何检索数据子集以及对数据进行排序。

最后，我们讨论了图像清理，并演示了几种修改图像数据的方法。这包括改变对比度、平滑、增亮和调整信息大小。最后，我们讨论了如何提取图像上的文字。

有了这个背景，我们将在下一章介绍基本的统计方法及其 Java 支持。