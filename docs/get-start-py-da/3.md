# 第三章。熊猫数据分析

在本章中，我们将探索另一个名为 Pandas 的数据分析库。本章的目标是给你一些基本知识和熊猫入门的具体例子。

# 熊猫套餐概述

Pandas 是一个 Python 包，支持快速、灵活和富有表现力的数据结构，以及用于数据分析的计算功能。以下是熊猫支持的一些突出功能:

*   带有标记轴的数据结构。这使得程序清晰明了，避免了因数据不一致而导致的常见错误。
*   对缺失数据的灵活处理。
*   大型数据集的智能基于标签的切片、花式索引和子集创建。
*   通过轴标签在自定义轴上进行强大的算术运算和统计计算。
*   对从文件、数据库或 HDF5 格式加载数据或将数据保存到文件、数据库或 HDF5 格式的强大输入和输出支持。

与 Pandas 安装相关，我们推荐一个简单的方法，那就是将其安装为 Anaconda 的一部分，Anaconda 是一个用于数据分析和科学计算的跨平台分发。可以参考[http://docs.continuum.io/anaconda/](http://docs.continuum.io/anaconda/)的参考资料下载安装库。

安装后，我们可以像其他 Python 包一样使用它。首先，我们必须在程序开始时导入以下包:

```py
>>> import pandas as pd
>>> import numpy as np

```

# 熊猫的数据结构

让我们首先了解熊猫的两个主要数据结构:系列和数据框架。他们可以处理金融、统计、社会科学和许多工程领域的大多数用例。

## 系列

A 系列是类似于表格中的数组、列表或列的一维对象。系列中的每个项目都分配给索引中的一个条目:

```py
>>> s1 = pd.Series(np.random.rand(4),
 index=['a', 'b', 'c', 'd'])
>>> s1
a    0.6122
b    0.98096
c    0.3350
d    0.7221
dtype: float64

```

默认情况下，如果没有通过索引，它将被创建为具有范围从`0`到`N-1`的值，其中`N`是序列的长度:

```py
>>> s2 = pd.Series(np.random.rand(4))
>>> s2
0    0.6913
1    0.8487
2    0.8627
3    0.7286
dtype: float64

```

我们可以通过使用索引来访问系列的值:

```py
>>> s1['c']
0.3350
>>>s1['c'] = 3.14
>>> s1['c', 'a', 'b']
c    3.14
a    0.6122
b    0.98096

```

这种访问方法类似于 Python 字典。因此，Pandas 还允许我们直接从 Python 字典中初始化 Series 对象:

```py
>>> s3 = pd.Series({'001': 'Nam', '002': 'Mary',
 '003': 'Peter'})
>>> s3
001    Nam
002    Mary
003    Peter
dtype: object

```

有时，我们希望过滤或重命名从 Python 字典创建的系列的索引。在这种情况下，我们可以将选定的索引列表直接传递给初始函数，类似于上面示例中的过程。只有索引列表中存在的元素才会出现在 Series 对象中。相反，字典中缺少的索引由 Pandas 初始化为默认的`NaN`值:

```py
>>> s4 = pd.Series({'001': 'Nam', '002': 'Mary',
 '003': 'Peter'}, index=[
 '002', '001', '024', '065'])
>>> s4
002    Mary
001    Nam
024    NaN
065    NaN
dtype:   object
ect

```

该库还支持检测缺失数据的功能:

```py
>>> pd.isnull(s4)
002    False
001    False
024    True
065    True
dtype: bool

```

同样，我们也可以从标量值初始化 Series:

```py
>>> s5 = pd.Series(2.71, index=['x', 'y'])
>>> s5
x    2.71
y    2.71
dtype: float64

```

系列对象也可以用 NumPy 对象初始化，如`ndarray`。此外，熊猫可以在算术运算中自动对齐以不同方式索引的数据:

```py
>>> s6 = pd.Series(np.array([2.71, 3.14]), index=['z', 'y'])
>>> s6
z    2.71
y    3.14
dtype: float64
>>> s5 + s6
x    NaN
y    5.85
z    NaN
dtype: float64

```

## 数据框

数据框是一个表格数据结构，包括一组有序的列和行。它可以被认为是一组共享一个索引(列名)的 Series 对象。有许多方法可以初始化数据框对象。首先，让我们看一下从列表字典创建数据帧的常见示例:

```py
>>> data = {'Year': [2000, 2005, 2010, 2014],
 'Median_Age': [24.2, 26.4, 28.5, 30.3],
 'Density': [244, 256, 268, 279]}
>>> df1 = pd.DataFrame(data)
>>> df1
 Density    Median_Age    Year
0  244        24.2        2000
1  256        26.4        2005
2  268        28.5        2010
3  279        30.3        2014

```

默认情况下，DataFrame 构造函数将按字母顺序排列列。我们可以通过将列的属性传递给初始化函数来编辑默认顺序:

```py
>>> df2 = pd.DataFrame(data, columns=['Year', 'Density', 
 'Median_Age'])
>>> df2
 Year    Density    Median_Age
0    2000    244        24.2
1    2005    256        26.4
2    2010    268        28.5
3    2014    279        30.3
>>> df2.index
Int64Index([0, 1, 2, 3], dtype='int64')

```

我们可以提供类似于系列的数据帧的索引标签:

```py
>>> df3 = pd.DataFrame(data, columns=['Year', 'Density', 
 'Median_Age'], index=['a', 'b', 'c', 'd'])
>>> df3.index
Index([u'a', u'b', u'c', u'd'], dtype='object')

```

我们也可以从嵌套列表中构建一个数据框架:

```py
>>> df4 = pd.DataFrame([
 ['Peter', 16, 'pupil', 'TN', 'M', None],
 ['Mary', 21, 'student', 'SG', 'F', None],
 ['Nam', 22, 'student', 'HN', 'M', None],
 ['Mai', 31, 'nurse', 'SG', 'F', None],
 ['John', 28, 'laywer', 'SG', 'M', None]],
columns=['name', 'age', 'career', 'province', 'sex', 'award'])

```

列可以像系列一样通过列名来访问，或者通过类似字典的符号来访问，或者如果列名是语法上有效的属性名，则作为属性来访问:

```py
>>> df4.name    # or df4['name'] 
0    Peter
1    Mary
2    Nam
3    Mai
4    John
Name: name, dtype: object

```

要在创建的数据框中修改或追加一个新列，我们需要指定列名和值:

```py
>>> df4['award'] = None
>>> df4
 name age   career province  sex award
0  Peter  16    pupil       TN    M  None
1    Mary  21  student       SG    F  None
2    Nam   22  student       HN  M  None
3    Mai    31    nurse        SG    F    None
4    John    28    lawer        SG    M    None

```

使用两种方法，可以按位置或名称检索行:

```py
>>> df4.ix[1]
name           Mary
age              21
career      student
province         SG
sex               F
award          None
Name: 1, dtype: object

```

数据框对象也可以从不同的数据结构中创建，如字典列表、系列字典或记录数组。初始化 DataFrame 对象的方法类似于上面的示例。

另一个常见的情况是从文本文件等位置向数据框提供数据。在这种情况下，我们使用`read_csv`函数，默认情况下，该函数期望列分隔符是逗号。但是，我们可以通过使用`sep`参数来改变这一点:

```py
# person.csv file
name,age,career,province,sex
Peter,16,pupil,TN,M
Mary,21,student,SG,F
Nam,22,student,HN,M
Mai,31,nurse,SG,F
John,28,lawer,SG,M
# loading person.cvs into a DataFrame
>>> df4 = pd.read_csv('person.csv')
>>> df4
 name   age   career   province  sex
0    Peter    16    pupil       TN        M
1    Mary     21    student     SG       F
2    Nam      22    student     HN       M
3    Mai      31    nurse       SG       F
4    John     28    laywer      SG       M

```

在读取数据文件时，我们有时希望跳过一行或一个无效值。至于熊猫`0.16.2`， `read_csv`支持超过 50 个参数来控制加载过程。一些常见的有用参数如下:

*   `sep`:这是列之间的分隔符。默认为逗号符号。
*   `dtype`:这是数据或列的数据类型。
*   `header`:设置行号作为列名。
*   `skiprows`:这将跳过文件开头要跳过的行号。
*   `error_bad_lines`:显示无效行(字段太多)，默认情况下会导致异常，因此不会返回数据帧。如果我们将该参数的值设置为`false`，将跳过不良行。

此外，Pandas 还支持直接从数据库读取数据帧或向数据库写入数据帧，如 Pandas 模块中的`read_frame`或`write_frame`功能。我们将在本章后面回到这些方法。

# 基本的基本功能

熊猫支持许多对操纵熊猫数据结构有用的基本功能。在这本书里，我们将集中探讨和分析最重要的特征。

## 重新标记和更改标签

重新索引是熊猫数据结构中的一个关键方法。它确认新的或修改的数据是否满足沿着熊猫对象特定轴的给定标签集。

首先，让我们查看一个系列对象的`reindex`示例:

```py
>>> s2.reindex([0, 2, 'b', 3])
0    0.6913
2    0.8627
b    NaN
3    0.7286
dtype: float64

```

当数据对象中不存在`reindexed`标签时，`NaN`的默认值将自动分配给该位置；数据框的情况也是如此:

```py
>>> df1.reindex(index=[0, 2, 'b', 3],
 columns=['Density', 'Year', 'Median_Age','C'])
 Density  Year  Median_Age        C
0      244  2000        24.2      NaN
2      268  2010        28.5      NaN
b      NaN   NaN         NaN      NaN
3      279  2014        30.3      NaN

```

我们可以通过设置`fill_value`参数将缺失索引情况下的`NaN`值更改为自定义值。让我们看看`reindex`函数支持的参数，如下表所示:

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

争吵

 | 

描述

 |
| --- | --- |
| `index` | 这是要符合的新标签/索引。 |
| `method` | 这是用于填充`reindexed`对象中的孔的方法。默认设置是未填充间隙。`pad/ffill`:向前填充值`backfill` / `bfill`:向后填充值`nearest`:使用最接近的值来填充间隙 |
| `copy` | 这将返回一个新对象。默认设置为`true`。 |
| `level` | 匹配传递的多索引级别上的索引值。 |
| `fill_value` | 这是用于缺失值的值。默认设置为`NaN`。 |
| `limit` | 这是`forward`或`backward`方法中要填充的最大尺寸间隙。 |

## 头尾

在常见的数据分析情况下，我们的数据结构对象包含很多列和大量行。因此，我们无法查看或加载对象的所有信息。熊猫支持允许我们检查小样本的功能。默认情况下，这些函数返回五个元素，但是我们也可以设置一个自定义数字。以下示例显示了如何显示较长序列的前五行和后三行:

```py
>>> s7 = pd.Series(np.random.rand(10000))
>>> s7.head()
0    0.631059
1    0.766085
2    0.066891
3    0.867591
4    0.339678
dtype: float64
>>> s7.tail(3)
9997    0.412178
9998    0.800711
9999    0.438344
dtype: float64

```

我们也可以用同样的方式对数据框对象使用这些函数。

## 二进制运算

首先，我们将考虑对象之间的算术运算。在不同的索引对象情况下，预期的结果将是索引对的并集。我们将不再解释这一点，因为我们在上面的部分(`s5 + s6`)中有一个关于它的例子。这一次，我们将展示另一个带有数据帧的示例:

```py
>>> df5 = pd.DataFrame(np.arange(9).reshape(3,3),0
 columns=['a','b','c'])
>>> df5
 a  b  c
0  0  1  2
1  3  4  5
2  6  7  8
>>> df6 = pd.DataFrame(np.arange(8).reshape(2,4), 
 columns=['a','b','c','d'])
>>> df6
 a  b  c  d
0  0  1  2  3
1  4  5  6  7
>>> df5 + df6
 a   b   c   d
0   0   2   4 NaN
1   7   9  11 NaN
2   NaN NaN NaN NaN

```

两种数据结构之间返回结果的机制相似。我们需要考虑的一个问题是对象之间缺少数据。在这种情况下，如果要填充一个固定值，如`0`，可以使用`add`、`sub`、`div`、`mul`等算术函数，以及函数支持的参数如`fill_value`:

```py
>>> df7 = df5.add(df6, fill_value=0)
>>> df7
 a  b   c   d
0  0  2   4   3
1  7  9  11   7
2  6  7   8   NaN

```

接下来，我们将讨论数据对象之间的 `comparison`操作。我们有一些支持的功能，比如 **等于** ( **eq** )、**不等于** ( **ne** )、**大于** ( **gt** )、**小于** ( **lt** )、**小于等于** ( **le** )和这里就是一个例子:

```py
>>> df5.eq(df6)
 a      b      c      d
0   True   True   True  False
1  False  False  False  False
2  False  False  False  False

```

## 功能统计

图书馆的支持的统计方法在数据分析中真的很重要。要进入大数据对象，我们需要知道一些汇总信息，如平均值、总和或分位数。熊猫支持大量计算它们的方法。让我们考虑一个计算`df5`的`sum`信息的简单例子，它是一个数据框对象:

```py
>>> df5.sum()
a     9
b    12
c    15
dtype: int64

```

当我们没有指定要计算 `sum`信息的轴时，默认情况下，该函数会在指数轴上计算，即轴`0`:

*   **系列**:我们不需要指定轴。
*   **数据框**:列(`axis = 1`)或索引(`axis = 0`)。默认设置为`axis 0`。

我们还有`skipna`参数，允许我们决定是否排除丢失的数据。默认设置为`true`:

```py
>>> df7.sum(skipna=False)
a    13
b    18
c    23
d   NaN
dtype: float64

```

我们要考虑的另一个功能是`describe()`。我们也可以非常方便地总结数据结构(如系列和数据框架)的大部分统计信息:

```py
>>> df5.describe()
 a    b    c
count  3.0  3.0  3.0
mean   3.0  4.0  5.0
std    3.0  3.0  3.0
min    0.0  1.0  2.0
25%    1.5  2.5  3.5
50%    3.0  4.0  5.0
75%    4.5  5.5  6.5
max    6.0  7.0  8.0

```

我们可以使用`percentiles`参数指定输出中包含或排除的百分位数；例如，考虑以下情况:

```py
>>> df5.describe(percentiles=[0.5, 0.8])
 a    b    c
count  3.0  3.0  3.0
mean   3.0  4.0  5.0
std    3.0  3.0  3.0
min    0.0  1.0  2.0
50%    3.0  4.0  5.0
80%    4.8  5.8  6.8
max    6.0  7.0  8.0

```

在这里，我们有一个熊猫中常见的支持统计函数的汇总表:

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

功能

 | 

描述

 |
| --- | --- |
| `idxmin(axis)`、`idxmax(axis)` | 这将计算具有最小或最大对应值的索引标签。 |
| `value_counts()` | 这将计算唯一值的频率。 |
| `count()` | 这将返回数据对象中非空值的数量。 |
| `mean()`、`median()`、`min()`、`max()` | 这返回数据对象中轴的平均值、中值、最小值和最大值。 |
| `std()`、`var()`、`sem()` | 这些返回平均值的标准偏差、方差和标准误差。 |
| `abs()` | 这将获取数据对象的绝对值。 |

## 功能应用

熊猫支持函数应用，允许我们在数据结构对象上应用其他包中支持的一些函数，比如 NumPy 或者我们自己的函数。这里我们举两个这种情况的例子，首先用`apply`执行`std()`函数，这是 NumPy 包的标准差计算函数:

```py
>>> df5.apply(np.std, axis=1)    # default: axis=0
0    0.816497
1    0.816497
2    0.816497
dtype: float64

```

其次，如果我们想将公式应用于数据对象，我们也可以通过以下步骤使用 apply 函数:

1.  定义要应用于数据对象的函数或公式。
2.  通过`apply`调用定义的函数或公式。在这一步中，我们还需要计算出我们想要应用计算的轴:

    ```py
    >>> f = lambda x: x.max() – x.min()    # step 1
    >>> df5.apply(f, axis=1)               # step 2
    0    2
    1    2
    2    2
    dtype: int64
    >>> def sigmoid(x):
     return 1/(1 + np.exp(x))
    >>> df5.apply(sigmoid)
     a           b         c
    0  0.500000  0.268941  0.119203
    1  0.047426  0.017986  0.006693
    2  0.002473  0.000911  0.000335

    ```

## 排序

有两种我们感兴趣的排序方式:按行或列索引排序和按数据值排序。

首先，我们将考虑按行和列索引排序的方法。在这种情况下，我们有`sort_index ()`功能。我们还有`axis`参数来设置函数是按行排序还是按列排序。带有`true`或`false`值的`ascending`选项将允许我们按升序或降序对数据进行排序。该选项的默认设置为`true`:

```py
>>> df7 = pd.DataFrame(np.arange(12).reshape(3,4), 
 columns=['b', 'd', 'a', 'c'],
 index=['x', 'y', 'z'])
>>> df7
 b  d   a   c
x  0  1   2   3
y  4  5   6   7
z  8  9  10  11
>>> df7.sort_index(axis=1)
 a  b   c  d
x   2  0   3  1
y   6  4   7  5
z  10  8  11  9

```

Series 有一个按值排序的方法顺序。对于对象中的`NaN`值，我们也可以通过`na_position`选项进行特殊处理:

```py
>>> s4.order(na_position='first')
024     NaN
065     NaN
002    Mary
001     Nam
dtype: object
>>> s4
002    Mary
001     Nam
024     NaN
065     NaN
dtype: object

```

除此之外，Series 还有`sort()`功能，按数值对数据进行排序。但是，该函数不会返回排序数据的副本:

```py
>>> s4.sort(na_position='first')
>>> s4
024     NaN
065     NaN
002    Mary
001     Nam
dtype: object

```

如果我们想对 DataFrame 对象应用排序函数，我们需要弄清楚哪些列或行将被排序:

```py
>>> df7.sort(['b', 'd'], ascending=False)
 b  d   a   c
z  8  9  10  11
y  4  5   6   7
x  0  1   2   3

```

如果不想将排序结果自动保存到当前数据对象，可以将`inplace`参数的设置改为`False`。

# 索引和选择数据

在本节中，我们将关注如何获取、设置或切片 Pandas 数据结构对象的子集。正如我们在前面几节中了解到的，系列或数据框对象具有轴标签信息。该信息可用于识别我们想要在对象中选择或分配新值的项目:

```py
>>> s4[['024', '002']]    # selecting data of Series object
024     NaN
002    Mary
dtype: object
>>> s4[['024', '002']] = 'unknown' # assigning data
>>> s4
024    unknown
065        NaN
002    unknown
001        Nam
dtype: object

```

如果数据对象是数据帧结构，我们也可以用类似的方式进行:

```py
>>> df5[['b', 'c']]
 b  c
0  1  2
1  4  5
2  7  8

```

对于数据框行的标签索引，我们使用`ix`函数，该函数使我们能够选择对象中的一组行和列。我们需要指定两个参数:我们想要获得的`row`和`column`标签。默认情况下，如果我们不指定选定的列名，该函数将返回包含对象中所有列的选定行:

```py
>>> df5.ix[0]
a    0
b    1
c    2
Name: 0, dtype: int64
>>> df5.ix[0, 1:3]
b    1
c    2
Name: 0, dtype: int64

```

此外，我们有许多方法来选择和编辑熊猫对象中包含的数据。下表总结了这些功能:

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

方法

 | 

描述

 |
| --- | --- |
| `icol`、`irow` | 这将按整数位置选择单行或单列。 |
| `get_value`、`set_value` | 这将按行或列标签选择或设置数据对象的单个值。 |
| `xs` | 这将按标签选择单个列或行作为系列。 |

### 型式

熊猫数据对象可能包含重复的索引。在这种情况下，当我们通过索引标签获取或设置数据值时，它将影响具有相同选定索引名称的所有行或列。

# 计算工具

让我们从两个数据对象之间的相关性和协方差计算开始。系列和数据框都有一个`cov`方法。在数据框对象上，此方法将计算对象内部系列之间的协方差:

```py
>>> s1 = pd.Series(np.random.rand(3))
>>> s1
0    0.460324
1    0.993279
2    0.032957
dtype: float64
>>> s2 = pd.Series(np.random.rand(3))
>>> s2
0    0.777509
1    0.573716
2    0.664212
dtype: float64
>>> s1.cov(s2)
-0.024516360159045424

>>> df8 = pd.DataFrame(np.random.rand(12).reshape(4,3), 
 columns=['a','b','c'])
>>> df8
 a         b         c
0  0.200049  0.070034  0.978615
1  0.293063  0.609812  0.788773
2  0.853431  0.243656  0.978057
0.985584  0.500765  0.481180
>>> df8.cov()
 a         b         c
a  0.155307  0.021273 -0.048449
b  0.021273  0.059925 -0.040029
c -0.048449 -0.040029  0.055067

```

相关方法的使用类似于协方差方法。在数据对象是数据帧的情况下，它计算数据对象中系列之间的相关性。然而，我们需要指定使用哪种方法来计算相关性。可用的方法有`pearson`、`kendall`和`spearman`。默认情况下，该功能应用`spearman`方法:

```py
>>> df8.corr(method = 'spearman')
 a    b    c
a  1.0  0.4 -0.8
b  0.4  1.0 -0.8
c -0.8 -0.8  1.0

```

我们还有`corrwith`功能，支持计算不同数据框对象中包含相同标签的系列之间的相关性:

```py
>>> df9 = pd.DataFrame(np.arange(8).reshape(4,2), 
 columns=['a', 'b'])
>>> df9
 a  b
0  0  1
1  2  3
2  4  5
3  6  7
>>> df8.corrwith(df9)
a    0.955567
b    0.488370
c         NaN
dtype: float64

```

# 处理缺失的数据

在本节中，我们将讨论熊猫数据结构中的缺失、`NaN`或`null`值。一个对象中缺少数据是很常见的情况。产生缺失数据的一种情况是重新索引:

```py
>>> df8 = pd.DataFrame(np.arange(12).reshape(4,3), 
 columns=['a', 'b', 'c'])
 a   b   c
0  0   1   2
1  3   4   5
2  6   7   8
3  9  10  11
>>> df9 = df8.reindex(columns = ['a', 'b', 'c', 'd'])
 a   b   c   d
0  0   1   2 NaN
1  3   4   5 NaN
2  6   7   8 NaN
4  9  10  11 NaN
>>> df10 = df8.reindex([3, 2, 'a', 0])
 a   b   c
3   9  10  11
2   6   7   8
a NaN NaN NaN
0   0   1   2

```

为了处理缺失值，我们可以使用`isnull()`或`notnull()`函数来检测序列对象以及数据帧对象中的缺失值:

```py
>>> df10.isnull()
 a      b      c
3  False  False  False
2  False  False  False
a   True   True   True
0  False  False  False

```

在系列中，我们可以使用`dropna`功能删除所有`null`数据和索引值:

```py
>>> s4 = pd.Series({'001': 'Nam', '002': 'Mary',
 '003': 'Peter'},
 index=['002', '001', '024', '065'])
>>> s4
002    Mary
001     Nam
024     NaN
065     NaN
dtype: object
>>> s4.dropna()    # dropping all null value of Series object
002    Mary
001     Nam
dtype: object

```

使用 DataFrame 对象，它比 Series 稍微复杂一点。我们可以知道要删除哪些行或列，以及是否所有条目都必须是`null`或单个`null`值就足够了。默认情况下，该函数将删除任何包含缺失值的行:

```py
>>> df9.dropna()    # all rows will be dropped
Empty DataFrame
Columns: [a, b, c, d]
Index: []
>>> df9.dropna(axis=1)
 a   b   c
0  0   1   2
1  3   4   5
2  6   7   8
3  9  10  11

```

控制缺失值的另一种方法是使用我们在上一节中介绍的函数的支持参数。它们对解决这个问题也非常有用。根据我们的经验，在创建数据对象时，我们应该在缺失的情况下分配一个固定值。这会让我们的物体在后面的加工步骤中更加干净。例如，考虑以下情况:

```py
>>> df11 = df8.reindex([3, 2, 'a', 0], fill_value = 0)
>>> df11
 a   b   c
3  9  10  11
2  6   7   8
a  0   0   0
0  0   1   2

```

我们也可以使用`fillna`函数来填充缺失值中的自定义值:

```py
>>> df9.fillna(-1)
 a   b   c  d
0  0   1   2 -1
1  3   4   5 -1
2  6   7   8 -1
3  9  10  11 -1

```

# 熊猫用于数据分析的高级用途

在本节中，我们将考虑一些高级熊猫用例。

## 分级索引

分级索引通过将数据对象组织成轴上的多个索引级别，为我们提供了一种在较低维度上处理较高维度数据的方法:

```py
>>> s8 = pd.Series(np.random.rand(8), index=[['a','a','b','b','c','c', 'd','d'], [0, 1, 0, 1, 0,1, 0, 1, ]])
>>> s8
a  0    0.721652
 1    0.297784
b  0    0.271995
 1    0.125342
c  0    0.444074
 1    0.948363
d  0    0.197565
 1    0.883776
dtype: float64

```

在前面的示例中，我们有一个具有两个索引级别的 Series 对象。可以使用`unstack`功能将对象重新排列成数据帧。在相反的情况下，可以使用`stack`功能:

```py
>>> s8.unstack()
 0         1
a  0.549211  0.420874
b  0.051516  0.715021
c  0.503072  0.720772
d  0.373037  0.207026

```

我们还可以创建一个数据框，在两个轴上都有一个分层索引:

```py
>>> df = pd.DataFrame(np.random.rand(12).reshape(4,3),
 index=[['a', 'a', 'b', 'b'],
 [0, 1, 0, 1]],
 columns=[['x', 'x', 'y'], [0, 1, 0]])
>>> df
 x                   y
 0         1         0
a 0  0.636893  0.729521  0.747230
 1  0.749002  0.323388  0.259496
b 0  0.214046  0.926961  0.679686
0.013258  0.416101  0.626927
>>> df.index
MultiIndex(levels=[['a', 'b'], [0, 1]],
 labels=[[0, 0, 1, 1], [0, 1, 0, 1]])
>>> df.columns
MultiIndex(levels=[['x', 'y'], [0, 1]],
 labels=[[0, 0, 1], [0, 1, 0]])

```

获取或设置具有多个索引级别的数据对象的值或子集的方法类似于非分层情况:

```py
>>> df['x']
 0         1
a 0  0.636893  0.729521
 1  0.749002  0.323388
b 0  0.214046  0.926961
0.013258  0.416101
>>> df[[0]]
 x
 0
a 0  0.636893
 1  0.749002
b 0  0.214046
0.013258
>>> df.ix['a', 'x']
 0         1
0  0.636893  0.729521
0.749002  0.323388
>>> df.ix['a','x'].ix[1]
0    0.749002
1    0.323388
Name: 1, dtype: float64

```

在将数据分组为多个索引级别后，我们还可以使用大部分带有级别选项的描述和统计功能，这些功能可以用来指定我们要处理的级别:

```py
>>> df.std(level=1)
 x                   y
 0         1         0
0  0.298998  0.139611  0.047761
0.520250  0.065558  0.259813
>>> df.std(level=0)
 x                   y
 0         1         0
a  0.079273  0.287180  0.344880
b  0.141979  0.361232  0.037306

```

## 面板数据

该面板是熊猫中三维数据的另一种数据结构。但是，它的使用频率低于系列或数据框。您可以将面板视为数据框对象的表格。我们可以从 3D `ndarray`或数据框对象的字典中创建面板对象:

```py
# create a Panel from 3D ndarray
>>> panel = pd.Panel(np.random.rand(2, 4, 5),
 items = ['item1', 'item2'])
>>> panel
<class 'pandas.core.panel.Panel'>
Dimensions: 2 (items) x 4 (major_axis) x 5 (minor_axis)
Items axis: item1 to item2
Major_axis axis: 0 to 3
Minor_axis axis: 0 to 4

>>> df1 = pd.DataFrame(np.arange(12).reshape(4, 3), 
 columns=['a','b','c'])
>>> df1
 a   b   c
0  0   1   2
1  3   4   5
2  6   7   8
9  10  11
>>> df2 = pd.DataFrame(np.arange(9).reshape(3, 3), 
 columns=['a','b','c'])
>>> df2
 a  b  c
0  0  1  2
1  3  4  5
6  7  8
# create another Panel from a dict of DataFrame objects
>>> panel2 = pd.Panel({'item1': df1, 'item2': df2})
>>> panel2
<class 'pandas.core.panel.Panel'>
Dimensions: 2 (items) x 4 (major_axis) x 3 (minor_axis)
Items axis: item1 to item2
Major_axis axis: 0 to 3
Minor_axis axis: a to c

```

面板中的每个项目都是一个数据框。我们可以通过项目名称选择一个项目:

```py
>>> panel2['item1']
 a   b   c
0  0   1   2
1  3   4   5
2  6   7   8
3  9  10  11

```

或者，如果我们想要通过轴或数据位置选择数据，我们可以使用`ix`方法，如在系列或数据框上:

```py
>>> panel2.ix[:, 1:3, ['b', 'c']]
<class 'pandas.core.panel.Panel'>
Dimensions: 2 (items) x 3 (major_axis) x 2 (minor_axis)
Items axis: item1 to item2
Major_axis axis: 1 to 3
Minor_axis axis: b to c
>>> panel2.ix[:, 2, :]
 item1  item2
a      6      6
b      7      7
c      8      8

```

# 总结

我们已经完成了熊猫数据分析库的基础知识。每当您了解用于数据分析的库时，您都需要考虑我们在本章中解释的三个部分。数据结构:熊猫库中有两种常见的数据对象类型；系列和数据帧。访问和操作数据对象的方法:Pandas 支持多种方法来选择、设置或切片数据对象的子集。但是，一般的机制是使用索引标签或项目的位置来标识值。功能和实用程序:它们是强大的库最重要的部分。在这一章中，我们介绍了 Pandas 的所有常见支持功能，这些功能允许我们轻松计算数据统计。该库还有许多其他有用的功能和实用程序，我们在本章中无法解释。如果你想扩展你对熊猫的经验，我们鼓励你开始自己的研究。它帮助我们以优化的方式处理大数据。在这本书的后面，你会看到更多的熊猫在行动。

到目前为止，我们已经了解了两个流行的 Python 库:NumPy 和 Pandas。熊猫是建立在 NumPy 上的，因此它允许更方便的数据交互。然而，在某些情况下，我们可以灵活地将两者结合起来，以实现我们的目标。

**练习练习**

链接[https://www.census.gov/2010census/csv/pop_change.csv](https://www.census.gov/2010census/csv/pop_change.csv)包含美国人口普查数据集。它有 23 列，每个美国州有一行，还有几行用于宏观区域，如北部、南部和西部。

*   将此数据集放入熊猫数据框。提示:跳过那些看起来没有帮助的行，例如注释或描述。
*   虽然数据集包含每十年的变化指标，但我们对二十世纪下半叶(即 1950 年至 2000 年)的人口变化感兴趣。在这一时间跨度内，哪个地区的人口增长最大，哪个地区的人口增长最小？还有，美国哪个州？

高级开放式练习:

*   在网上查找更多人口普查数据；不仅仅是美国，还有世界各国。也试着寻找同期的国内生产总值数据。尝试调整这些数据来探索模式。GDP 和人口增长是如何关联的？有什么特殊情况吗？比如 GDP 高但人口增长低的国家还是历史相反的国家？